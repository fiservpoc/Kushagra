{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textract\n",
    "import os\n",
    "import pandas as pd \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import docx2txt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re\n",
    "from sklearn.model_selection import train_test_splits\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_directory = \"C:/Users/NEW/Desktop/Udemy/dataset\"\n",
    "path=[]\n",
    "dir1=[]\n",
    "content=[]\n",
    "clean=[]\n",
    "s = \"abc \\n \\t \\t\\t \\t \\n  efg\"\n",
    "df=pd.DataFrame()\n",
    "for skill in os.listdir(parent_directory):  \n",
    "        skill_dir=os.path.join(parent_directory, skill)\n",
    "        for resume in os.listdir(skill_dir):\n",
    "            file=os.path.join(skill_dir, resume)\n",
    "            content.append(docx2txt.process(file))\n",
    "            clean.append(re.sub('\\s+', ' ',docx2txt.process(file)))            \n",
    "            path.append(file)\n",
    "            dir1.append(skill)\n",
    "            \n",
    "df['path']=path\n",
    "df['tag']=dir1\n",
    "df['content']=content\n",
    "df['content1']=clean\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>tag</th>\n",
       "      <th>content</th>\n",
       "      <th>content1</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/NEW/Desktop/Udemy/dataset\\Rejected\\Gi...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>Gitika Mishra\\t\\t\\t             Phone: +91-893...</td>\n",
       "      <td>Gitika Mishra Phone: +91-8939340040 Email: git...</td>\n",
       "      <td>8805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/NEW/Desktop/Udemy/dataset\\Rejected\\Je...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>Jeweel Roy\\n\\nEmail: royjeweel@gmail.com\\n\\nMo...</td>\n",
       "      <td>Jeweel Roy Email: royjeweel@gmail.com Mob: 844...</td>\n",
       "      <td>3674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/NEW/Desktop/Udemy/dataset\\Rejected\\Ra...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>Ravi Shankar\\n\\nContact No: - +91-9347782203\\n...</td>\n",
       "      <td>Ravi Shankar Contact No: - +91-9347782203 Emai...</td>\n",
       "      <td>8363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/NEW/Desktop/Udemy/dataset\\Rejected\\Sh...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>Shruti Tembhurnikar\\n\\nMobile: 9890844834     ...</td>\n",
       "      <td>Shruti Tembhurnikar Mobile: 9890844834 # E-Mai...</td>\n",
       "      <td>6562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/NEW/Desktop/Udemy/dataset\\Rejected\\Sn...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>Snehal Giri\\n\\nE-mail:  snehalgiri11@yahoo.com...</td>\n",
       "      <td>Snehal Giri E-mail: snehalgiri11@yahoo.com Mob...</td>\n",
       "      <td>7291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C:/Users/NEW/Desktop/Udemy/dataset\\Selected\\Bi...</td>\n",
       "      <td>Selected</td>\n",
       "      <td>RESUME\\n\\n\\n\\n\\n\\nName:  Bibhudatta Hotta\\n\\nD...</td>\n",
       "      <td>RESUME Name: Bibhudatta Hotta Designation: IT ...</td>\n",
       "      <td>6220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C:/Users/NEW/Desktop/Udemy/dataset\\Selected\\Bi...</td>\n",
       "      <td>Selected</td>\n",
       "      <td>Bikash Singh\\n\\n\\t\\t\\t\\t\\t\\t                  ...</td>\n",
       "      <td>Bikash Singh Bikash.IT19@gmail.com Mobile: 808...</td>\n",
       "      <td>8021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C:/Users/NEW/Desktop/Udemy/dataset\\Selected\\So...</td>\n",
       "      <td>Selected</td>\n",
       "      <td>Sourabh Muchhal\\n\\nE-Mail: sourabh_muchhal@yah...</td>\n",
       "      <td>Sourabh Muchhal E-Mail: sourabh_muchhal@yahoo....</td>\n",
       "      <td>6899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C:/Users/NEW/Desktop/Udemy/dataset\\Selected\\Vi...</td>\n",
       "      <td>Selected</td>\n",
       "      <td>Vivek G Shilimkar\\n\\nMobile number: 8551905575...</td>\n",
       "      <td>Vivek G Shilimkar Mobile number: 8551905575/75...</td>\n",
       "      <td>4516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path       tag  \\\n",
       "0  C:/Users/NEW/Desktop/Udemy/dataset\\Rejected\\Gi...  Rejected   \n",
       "1  C:/Users/NEW/Desktop/Udemy/dataset\\Rejected\\Je...  Rejected   \n",
       "2  C:/Users/NEW/Desktop/Udemy/dataset\\Rejected\\Ra...  Rejected   \n",
       "3  C:/Users/NEW/Desktop/Udemy/dataset\\Rejected\\Sh...  Rejected   \n",
       "4  C:/Users/NEW/Desktop/Udemy/dataset\\Rejected\\Sn...  Rejected   \n",
       "5  C:/Users/NEW/Desktop/Udemy/dataset\\Selected\\Bi...  Selected   \n",
       "6  C:/Users/NEW/Desktop/Udemy/dataset\\Selected\\Bi...  Selected   \n",
       "7  C:/Users/NEW/Desktop/Udemy/dataset\\Selected\\So...  Selected   \n",
       "8  C:/Users/NEW/Desktop/Udemy/dataset\\Selected\\Vi...  Selected   \n",
       "\n",
       "                                             content  \\\n",
       "0  Gitika Mishra\\t\\t\\t             Phone: +91-893...   \n",
       "1  Jeweel Roy\\n\\nEmail: royjeweel@gmail.com\\n\\nMo...   \n",
       "2  Ravi Shankar\\n\\nContact No: - +91-9347782203\\n...   \n",
       "3  Shruti Tembhurnikar\\n\\nMobile: 9890844834     ...   \n",
       "4  Snehal Giri\\n\\nE-mail:  snehalgiri11@yahoo.com...   \n",
       "5  RESUME\\n\\n\\n\\n\\n\\nName:  Bibhudatta Hotta\\n\\nD...   \n",
       "6  Bikash Singh\\n\\n\\t\\t\\t\\t\\t\\t                  ...   \n",
       "7  Sourabh Muchhal\\n\\nE-Mail: sourabh_muchhal@yah...   \n",
       "8  Vivek G Shilimkar\\n\\nMobile number: 8551905575...   \n",
       "\n",
       "                                            content1  length  \n",
       "0  Gitika Mishra Phone: +91-8939340040 Email: git...    8805  \n",
       "1  Jeweel Roy Email: royjeweel@gmail.com Mob: 844...    3674  \n",
       "2  Ravi Shankar Contact No: - +91-9347782203 Emai...    8363  \n",
       "3  Shruti Tembhurnikar Mobile: 9890844834 # E-Mai...    6562  \n",
       "4  Snehal Giri E-mail: snehalgiri11@yahoo.com Mob...    7291  \n",
       "5  RESUME Name: Bibhudatta Hotta Designation: IT ...    6220  \n",
       "6  Bikash Singh Bikash.IT19@gmail.com Mobile: 808...    8021  \n",
       "7  Sourabh Muchhal E-Mail: sourabh_muchhal@yahoo....    6899  \n",
       "8  Vivek G Shilimkar Mobile number: 8551905575/75...    4516  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length']=df['content1'].apply(len)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['length'].plot.hist(bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization(list of important words)\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Gitika, Mishra, Phone, 918939340040, Email, g...\n",
       "1    [Jeweel, Roy, Email, royjeweelgmailcom, Mob, 8...\n",
       "2    [Ravi, Shankar, Contact, 919347782203, Email, ...\n",
       "3    [Shruti, Tembhurnikar, Mobile, 9890844834, EMa...\n",
       "4    [Snehal, Giri, Email, snehalgiri11yahoocom, Mo...\n",
       "Name: content1, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content1'].head(5).apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2103\n"
     ]
    }
   ],
   "source": [
    "bow_transformer = CountVectorizer(analyzer=text_process).fit(df['content1'])\n",
    "\n",
    "# Print total number of vocab words\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Resume_bow = bow_transformer.transform(df['content1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2096)\t0.1343899626648496\n",
      "  (0, 2094)\t0.017947198876903155\n",
      "  (0, 2091)\t0.059959288094453125\n",
      "  (0, 2083)\t0.022398327110808268\n",
      "  (0, 2072)\t0.08746783099793841\n",
      "  (0, 2070)\t0.029155943665979466\n",
      "  (0, 2062)\t0.05070050276164739\n",
      "  (0, 2058)\t0.03451976568198546\n",
      "  (0, 2057)\t0.03451976568198546\n",
      "  (0, 2054)\t0.08773564409287031\n",
      "  (0, 2046)\t0.0731130367440586\n",
      "  (0, 2042)\t0.025350251380823696\n",
      "  (0, 2041)\t0.044796654221616536\n",
      "  (0, 2032)\t0.029155943665979466\n",
      "  (0, 2024)\t0.029155943665979466\n",
      "  (0, 2019)\t0.03451976568198546\n",
      "  (0, 2018)\t0.029155943665979466\n",
      "  (0, 2016)\t0.03589439775380631\n",
      "  (0, 2010)\t0.03451976568198546\n",
      "  (0, 2002)\t0.05070050276164739\n",
      "  (0, 2001)\t0.07605075414247109\n",
      "  (0, 1997)\t0.07178879550761262\n",
      "  (0, 1995)\t0.03451976568198546\n",
      "  (0, 1994)\t0.029155943665979466\n",
      "  (0, 1992)\t0.03451976568198546\n",
      "  :\t:\n",
      "  (0, 157)\t0.03451976568198546\n",
      "  (0, 148)\t0.029155943665979466\n",
      "  (0, 141)\t0.025350251380823696\n",
      "  (0, 132)\t0.022398327110808268\n",
      "  (0, 126)\t0.03451976568198546\n",
      "  (0, 122)\t0.025350251380823696\n",
      "  (0, 120)\t0.13807906272794185\n",
      "  (0, 107)\t0.03451976568198546\n",
      "  (0, 106)\t0.03451976568198546\n",
      "  (0, 89)\t0.03451976568198546\n",
      "  (0, 87)\t0.03451976568198546\n",
      "  (0, 85)\t0.05070050276164739\n",
      "  (0, 68)\t0.014622607348811718\n",
      "  (0, 54)\t0.019986429364817707\n",
      "  (0, 42)\t0.025350251380823696\n",
      "  (0, 32)\t0.03451976568198546\n",
      "  (0, 29)\t0.0485422112389858\n",
      "  (0, 25)\t0.03451976568198546\n",
      "  (0, 20)\t0.03451976568198546\n",
      "  (0, 19)\t0.06903953136397092\n",
      "  (0, 17)\t0.029155943665979466\n",
      "  (0, 15)\t0.03451976568198546\n",
      "  (0, 13)\t0.06903953136397092\n",
      "  (0, 10)\t0.03451976568198546\n",
      "  (0, 4)\t0.03451976568198546\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer().fit(Resume_bow)\n",
    "tfidf4 = tfidf_transformer.transform(bow4)\n",
    "print(tfidf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6931471805599454\n",
      "1.2231435513142097\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_transformer.idf_[bow_transformer.vocabulary_['MSBI']])\n",
    "print(tfidf_transformer.idf_[bow_transformer.vocabulary_['server']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (9, 2103)\n",
      "Amount of Non-Zero occurences:  3589\n"
     ]
    }
   ],
   "source": [
    "Resume_tfidf = tfidf_transformer.transform(Resume_bow)\n",
    "print('Shape of Sparse Matrix: ', Resume_tfidf.shape)\n",
    "print('Amount of Non-Zero occurences: ', Resume_tfidf.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "Resume_selection_model = MultinomialNB().fit(Resume_tfidf, df['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: Rejected\n",
      "expected: Rejected\n"
     ]
    }
   ],
   "source": [
    "print('predicted:', Resume_selection_model.predict(tfidf4)[0])\n",
    "print('expected:', df.tag[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rejected' 'Rejected' 'Rejected' 'Rejected' 'Rejected' 'Selected'\n",
      " 'Selected' 'Selected' 'Selected']\n"
     ]
    }
   ],
   "source": [
    "all_predictions = Resume_selection_model.predict(Resume_tfidf)\n",
    "print(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Rejected       1.00      1.00      1.00         5\n",
      "    Selected       1.00      1.00      1.00         4\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         9\n",
      "   macro avg       1.00      1.00      1.00         9\n",
      "weighted avg       1.00      1.00      1.00         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(df['tag'], all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 3 9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "resum_train, resum_test, tag_train, tag_test = \\\n",
    "train_test_split(df['content1'], df['tag'], test_size=0.3)\n",
    "\n",
    "print(len(resum_train), len(resum_test), len(tag_train) + len(tag_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('bow', CountVectorizer(analyzer=<function text_process at 0x0000025479A3A2F0>,\n",
       "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocesso...f=False, use_idf=True)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(resum_train,tag_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(resum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Rejected       1.00      0.67      0.80         3\n",
      "    Selected       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.67      0.67      0.67         3\n",
      "   macro avg       0.50      0.33      0.40         3\n",
      "weighted avg       1.00      0.67      0.80         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NEW\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\NEW\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\NEW\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions,tag_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1],\n",
       "       [0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(predictions,tag_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
