{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:/Users/NEW/Desktop/Udemy/Resume\\\\Divya_Resume.docx', 'C:/Users/NEW/Desktop/Udemy/Resume\\\\kushagra cv .docx', 'C:/Users/NEW/Desktop/Udemy/Resume\\\\Kushagra Resume_4 Yrs_ ETL-BI Tester.docx', 'C:/Users/NEW/Desktop/Udemy/Resume\\\\Mohammed Imran Shaikh_CV.docx', 'C:/Users/NEW/Desktop/Udemy/Resume\\\\Resume_4years Experienced_QA.docx', 'C:/Users/NEW/Desktop/Udemy/Resume\\\\Resume_Ch_June - Copy.docx', 'C:/Users/NEW/Desktop/Udemy/Resume\\\\Resume_Ch_June.docx']\n"
     ]
    }
   ],
   "source": [
    "files_path = \"C:/Users/NEW/Desktop/Udemy/Resume\"\n",
    "read_files = glob.glob(os.path.join(files_path,\"*.docx\"))\n",
    "print(read_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['R E S U M E', '', 'DIVYA SHARma', 'SUMMARY', '', 'Work Experience', 'academics', '', 'SKILLS', '', '', '', '', 'Company: IBM India Pvt Ltd', 'PROJECT DETAILS ', '', 'Project 1 : DLG Emerald Integration', 'Client: Direct Line Group Insurance, UK', 'Duration: Sep’14 to Oct’16.', 'Technology: Mule ESB ', '', 'Environment: AnyPoint Studio, Mule Studio, Soap UI, SVN, JAVA.', 'Project Overview:  The intent of this project is to develop middleware services for DLG using Mule, JMS, and Oracle DB which will be used to bridge DLG GW Systems & Third Party services.\\xa0', 'Roles and Responsibilities: ', '', 'Responsible for being in the project team in delivering solution to our customer in the', ' Insurance Sector.', 'Deliver new and complex high quality solutions to clients in response to varying business requirements.', 'Responsible for effective communication between the project team and the customer.', '', 'Project 2 : Sprint Account', 'Client: Sprint Telecommunications, US', 'Duration: Nov’16 to till date.', 'Technology: Mule ESB ', '', 'Environment: AnyPoint Studio, Mule Studio, Soap UI, SVN, JAVA, RAML', 'Project Overview:  The intent of this project is to develop REST API using RAML and calling Third Party services.', 'Roles and Responsibilities: ', '', 'Responsible for developing API using RAML to the customer in Telecom Sector.', 'Coding, unit testing the components, functional testing.', 'Delivering the code with high standards, quality and delivered it with in the time lines.', '', '', 'CERTIFICATION', '', 'Certified as MCD Integration and API Associate.(Mule 3.7) with 91.25%', '', 'PERSONAL DETAILS:', '\\t\\t\\t\\t\\t\\t\\tSignature'], ['KUSHAGRA  ', '59-D SHIPRA SUNCITY, INDRAPURAM,                                                                                                                                                             ', 'GHAZIABAD (U.P.)                                                                                    ', ' 09990916443                                                                                                           ', 'E-mail: kushagra116@gmail.com', '                                             ', '                                                                             ', 'Career Snapshot', '', '                Seeking employment that allows me to grow professionally, while being able to utilize my skills for the betterment of the organization with the best use of my dedication, determination and resourcefulness.', '', '', 'Academics ', '', 'BACHELOR DEGREE', 'Bachelor in Electronics and Communication Engineering (2009-13),', 'Saroj Institute Lucknow, Affiliated to U.P Technical University,                          65.7%. ', '', 'HIGHER SECONDARY SCHOOL', 'St. Patricks School(2009), Affiliated to CBSE,                                                  63.6%.', '', 'HIGH SCHOOL', 'St. Patricks School(2007), Affiliated to CBSE,                                                  71.2%.', '', '', 'Projects', '', 'MINI PROJECT    ', '     Title               :    PCB Designing', '      Description     :    PCB Designing of  5 volt power supply where i learned about soldering process on printed circuit board .', ' ', 'ACADMIC PROJECT ', '     Title               :    Password Based Automatic Door Lock System', '     Period\\t     :    3 months', '      Description    : ', '                    Password Based Automatic Door Lock System is an access control system that allows only authorized persons to access the restricted area. The system is fully controlled by the 8 bit microcontroller AT89C2051 which has a 2 Kbytes of ROM for program memory. The system has a keypad through which password is entered. When the entered password matches the password stored in memory then the gate gets opened. If  the entered password is wrong buzzer starts.   ', '', '', 'Summer  Training', '', 'Three month training on Core Java from Trainedge (in partnership with IBM) and received A+ Grade .', 'One month training in Uttar Pradesh Power Co-operation Ltd.(UPPCL), Lucknow.', 'IT Proficiency', '', 'Programming Languages:  C, C++, Core Java.', '', '', 'Workshop', '', 'PCB and schematic design workshop from LABSGURU technologies Pvt. Ltd.  Lucknow.', 'Embedded System workshop from CETPA Infotech Pvt. Ltd. Lucknow', '.', 'Extra Curricular Activity', '', 'Paticipated in all college cultural events like fresher’s & fest & Won 2nd and 3rd  Prize in dancing.', 'Participated in various debate competitions and done Anchoring.', 'Participated in Campus Connect Mega Cultural Event.', '', 'Hobbies', '', 'Dancing & singing.', 'Listening Music & Travelling.', 'Playing PC Games.', '', '', 'Personal Details', '      ', '          Father’s Name\\t          :  Mr. Ram Murat', '        Date of Birth\\t          :  7th August , 1990', '      Gender\\t\\t          :  Male', '      Languages Known         :  English, Hindi  ', '      Permanent Address        :  S/O Mr. Ram Murat, Kuber Garments Harlalka Road,', '                                            Jaunpur- 222001 (U.P.)', '', '', 'Declaration', '', 'I hereby declare that the above-mentioned information is correct up to my knowledge and I bear the responsibility for the correctness of the above-mentioned particulars.', '', '', '', '', 'PLACE\\xa0:-                                                                                                                  ', 'DATE\\xa0:-                                                                                                  Kushagra', ''], ['', '', '', 'KUSHAGRA', 'Senior ETL Test Analyst', 'Email: Kushagra0708@gmail.com', 'Mob: 09004844497', '', '', 'SYNOPSIS: Seeking for an excellent opportunity to work as a Tester where my talent and knowledge can be best utilized for the development of the organization', '', 'EXPERIENCE SUMMARY', '', 'Having 4 years of experience in ETL/BI with Adrosonic and Capgemini India.', 'In depth knowledge of ETL/BI and Data Warehousing Concepts and strong knowledge in complex SQL queries.', 'Expert in all type of ETL/BI testing Scenarios viz., all validation (mapping, schema, constrain, null, duplicate, checksum,) and full load testing, incremental testing, Report validation.', 'Expertise in different levels of testing viz., System Integration, Regression, Retesting, STLC, Defect Life Cycle and Agile Methodology. ', 'Created Automating Test Script creation via Macro.', 'Excellent Analytical and Logical skills with effective communication and writing skills.', '', 'Work Profile', '', 'Senior ETL Test Analyst at Adrosonic IT Consultancy\\t\\t19thsept 2017 to present', 'Senior Software Engineer at Capgemini India\\t\\t\\t\\t26thJune 2014 to 18thsep 2017', '', 'Certifications and Achievements', '', 'Trained in ETL/BI/Functional Testing from IGate Corporate University(now merged with Capgemini).\\t', 'Certification of E-business Suite Technical Training covered Core Java, OracleForm & Reports,OAF,ADF from AlmaMate Training Institute, Noida.', 'Certification of Core Java Programming fromTrainedge(in Partner with IBM).', 'Received Pat on the Back for outstanding project deliverables.', 'Received appreciations from Client and Project Managers for outstanding performance in project.', '', 'Skill Set:', '', '', '', 'Qualification:', '', \"Bachelor's Degree in Electronics and Communication with a score of 74.65% in the final year from Uttar Pradesh Technical University (2012-13), Aggregate of 65.7%\", '', '', '', 'PROJECT EXPERIENCE (Adrosonic)', '', 'Project Name: Ship-owners Data Warehouse testing\\xa0', 'Time Period: Sept 2017- Till date', 'Tools:SQL server 2012, Talend, Apache Superset , Jira', 'Description: Ship-owners are one of the seven ship insurance company in the world. They have many application/websites e.g  Utom, Sigma, Broker Maintenance different role and their respective database  . They are creating data warehouse for all the application, and these application act as source to them. For visualization they are using Apache Superset.', 'Role and Responsibilities:', 'Understanding business requirement', 'Understanding mapping sheet of each source and physical data model of entire data warehouse', 'Data Transformation Testing, Full load /Incremental testing ,DB Schema of Source & Target, Mapping doc validation, Duplicate Check, Reports validation', 'Data validation Btw source to stage, stage to warehouse, Warehouse to View, reports validation', 'Microsoft CRM Online to Data warehouse validation.', 'Handled entire project single handedly from testing side.', 'Daily Client interaction in Scrum meeting, Sending D.S.R and W.S.R', '', 'PROJECT EXPERIENCE (Capgemini)', 'Project 1', 'Project Name: \\tSTRATEGIC DATA STORE- Capgemini', 'Client:\\t\\tWillis Insurance Company, UK', 'Role:          \\tSenior Software Engineer', 'Duration:         19 months', 'Tools   :             SQL Server, Team Foundation server (TFS) ', 'Description:', 'This is project from insurance domain, for creating a data warehouse having three data marts i.e. Claims, Coverage and Exposure .Here we are fetching the client data from different source. We are having different data layers Staging, Retention and Data store. From source to staging we do a truncate load and for other layers we do incremental load. Here we are building data warehouse having three data mart for client i.e. Claims, Coverage and Exposure.', '', 'Roles and Responsibilities:', 'Assigning task to other team members.', 'My role is an ETL tester, where I use to validate Extract, transform and load process in the project. ', 'Involved in testing after execution of packages for validating the technical as well as functional accuracy in the packages.', 'Analyzing business requirement, creating test scenarios, test cases, Defect tracking.', 'Writing Complex Queries and analyzing them.', 'Daily customer interaction via calls and Emails.', 'Daily Status reporting and weekly status reporting to Customer and Senior Management.', 'Timely Presentation and Knowledge transfer to junior team members.', 'Division and Assignment of Tasks to be performed by Team members.', 'Successfully delivered Strategic Data Store Releases to production without any major issues. ', '', 'Project 2', 'Project Name: iAware (Integrated Analytics and Warehousing -Capgemini)', 'Role                   Senior Software Engineer', 'Duration           6 Months', 'Tools   :             SQL Server, ODL Hive, HP- QC', '', 'Description:', 'The main objective of this project is to load the data that contain the details of clinical operation into the iAware Operational Data Warehouse (ODW) from ODL source after transforming the data as per the requirements provided.', 'Roles and Responsibilities:', 'Performing manual testing by performing the operations mentioned in the design steps. Compared the expected results with the actual outcome and recorded the results. ', 'Co-coordinating with counterparts in understanding/gathering requirements & resolving queries.', 'Responsible for creating complete test Scenarios, test data, and reporting status ensuring accurate coverage of requirements and business processes. ', 'Defect management, Requirement analysis', 'Collaborating with the developers and discussing over the requirements and defects', 'Test Estimation Involved in the calls with Developers as well as BA for information gathering. ', 'Identify risks and provide mitigation plan. Escalate issues on timely manner to management.', 'Verified the data in target database by ETL process. ', 'Verified column mapping between source and target', '', 'Project 3', 'Project Name\\t: PACT (Capgemini)\\t\\t\\t\\t', 'Duration\\t: 7 months', 'Client    \\t: Willis Insurance Company, UK', 'Back End             : SQL Server Management Studio', 'Defect Tracking : Quality Center 11.0, TFS\\t', 'Role\\t\\t:  Software Engineer', '', 'Description:', 'This is project from insurance domain, for creating a data warehouse for all the policy from different sources. Here we were having pre staging, Staging and Pact layer (final data warehouse). There we were receiving data from 18 different sources. One front end dash board application was also included for monitoring status of all jobs depending on source.', '', 'Key Responsibilities\\t', 'Complete Ownership of Critical Reference Data Module', 'Analysis of Business Requirement, Creation of Test Scenarios, Test Cases, Requirement and Mapping and Defect Tracking', 'Writing Complex Queries and analyzing them', 'Daily Customer interaction via calls and emails', 'Daily Status Reporting and Weekly Status Reporting to the Customer and Senior Management', 'Timely Presentations and knowledge transfer to junior team members', 'Successfully delivered Reference Data Releases to Production without any major issues.', '', '', 'Project 4', 'Project Name: PLUW reporting(Capgemini)', 'Role:                  Software Engineer', 'Duration:          5 months', 'Tools   :              SQL Server, MTM', '', 'Description:', 'This project is about creating a Data warehouse and generation report for Client i.e. CHUBB. Here data acquisition is done from 8 different sources of client. At stage layer data integration done and transformation at Data store layer. At stage truncate and load is done. At incremental load is done. Total 64 reports were generated, 8 reports from each source system. These each 64 reports were generated as per different business requirement. ', '', 'Roles and Responsibilities:', '', 'Complete Ownership of PLUW reporting Module', 'Analysis of Business Requirement, Creation of Test Scenarios, Test Cases, Requirement and Mapping and Defect Tracking', 'Writing Complex Queries and analysing them', 'Daily Customer interaction via calls and emails', 'Daily Status Reporting and Weekly Status Reporting to the Customer and Senior Management', 'Timely Presentations and knowledge transfer to junior team member', 'Successfully delivered PLUW reporting Releases to Production without any major issues', 'Identified Functional requirement and prepared the SQL queries based on business requirements.', 'Reporting to the onsite coordinator about the status of the daily task.', 'Interacting with the onsite people and resolving the offshore issues.', 'Attending weekly status meetings and provide detailed status report to the client.', '', '', 'Personal Details:', '', '', 'I hereby declare that the information that I have furnished is authentic, and true to the best of my knowledge.', '', '', 'KUSHAGRA', ''], ['Mohammed Imran Shaikh', '\\nEmail Id: - immushaikh11@gmail.com ', 'Address: - Room No: - 7/8, Municipal Chawl 154 –C, Dharavi Main Road, Dharavi, Mumbai-400017\\nContact No: - +91- 8097717817', '__________________________________________________________________________________\\n', 'Career Objective:\\nTo work as a BI (Business Intelligence) developer in an organization where I can utilize my existing skills and knowledge and develop new skills to contribute in the accomplishment of organizational goals.\\n\\nCareer Summary:', 'Currently working with ‘Capgemini India Pvt. Ltd’ as a Senior Software Engineer.', '2 years of experience as a MSBI (Microsoft Business Intelligence) developer.', 'Developed dashboards containing multiple reports linked together using SSRS (SQL Server Reporting Services).', 'Good knowledge of SSIS (SQL Server Integration Services).', 'Experience of writing Stored Procedures to implement complex business logics.', 'Familiar with the Data Warehousing concepts such as Staging, Referential Integrity, SCD etc.', 'In depth knowledge of ETL (Extract, Transform & Load) testing involving complex joins and transformations.', 'Trained in Oracle (SQL/PLSQL) 11g, Informatica Power Center, Business Object XI, OBIEE and Unix from Capgemini Corporate University (Formerly known as IGATE Corporate University)\\n', 'Personality Traits:', 'Hardworking, punctual and sincere at workplace.', 'Ability to work with team and individuals as well.', 'Ability to accomplish the assigned tasks within the specified timelines.', ' Effective liaison with the customer.', 'Good Communication skills.', '\\nKey Responsibilities Handled:', 'Worked as a solo resource in my first project for analyzing requirements, developing reports (SSRS) and coordinating with the clients.', 'Developed user friendly SSRS reports with navigation functionality.', 'Responsibility of a single DB resource to ensure proper implementation of business logics/rules', 'using Stored Procedures.', 'Writing SQL queries involving complex joins to match data between source and target DB.', 'To interact with the clients to clarify requirements and follow-up on outstanding items.', 'Making Minutes of Meeting (MOM) of the daily status call with the client.', '', 'Guiding the team members by explaining the ETL & data warehousing concepts and helping them write SQL queries', 'Hands on experience on ETL tools like Informatica and SSIS.', 'Hands on experience on reporting tools like BOXI and OBIEE.', '\\nTechnical Skills:', 'Reporting Tools : SSRS, BOXI, OBIEE', 'ETL Tools : Informatica & SSIS', 'Databases : SQL Server, Oracle (SQL/PLSQL) 11g, MS Access', 'Basics of Excel VBA (Macros)', '', 'Achievements: ', 'Felicitated with the ‘IEVOLVE Shining Star’ certificate of Capgemini for creating Macros to match source and target table CheckSum values.\\n\\nAcademia:\\nB.E in Electronics and Telecommunication Engineering from Mumbai University with 1st Class.', '\\nExtra Curricular activities:', 'Associated with many NGOs working for the betterment of society and mankind.\\n', 'Personal Details:\\nDate of Birth : 12-04-1993\\nNationality : Indian\\xa0\\nLanguages known : English, Hindi, Marathi, Tamil', '', 'I hereby declare that all above details furnished are true and correct to the best of my knowledge and belief.', 'Place: Mumbai', 'Date: 20-03-2016', '\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tSignature', '', '\\t\\t\\t\\t\\t\\t\\t\\t\\t(Mohammed Imran Shaikh)', '', ''], ['', 'Shashi Singh', 'Mob. 7506264138', ' ', '', '', 'OBJECTIVE:', 'To achieve a challenging position in the industry by utilizing my skills, in achieving organization’s goal and thereby enhancing my knowledge and gaining valuable experience.', 'SYNOPSIS:', 'Highly motivated ETL Tester.  Having 4 Years of experience in QA- ETL Testing, Manual Testing with Capgemini India Pvt. Ltd. ', ' \\t', 'Having 4 years of experience as a QA- ETL Testing, Manual Testing and CRM Tester.', 'Good knowledge of ETL concepts and process, HiveQL, BTEQ, SQL queries and basic UNIX commands.', 'Experience in different areas of Data Warehouse Testing in Retail & Insurance domain.', 'Expertise in different levels of testing viz., I-Pad testing, Mobile Application testing, Database testing, Data Warehouse and Defect tracking.', 'Also having good knowledge of performance testing using JMeter.', 'Extensive working experience on Test management and Defect Tracking Tools – HP ALM.', 'Good database knowledge and working experience in SQL Server, Teradata and ODL HIVE.', 'Expertise in preparing Test data and Test scenarios.', 'Excellent Analytical and Logical skills with effective communication and writing skills', '', 'TECHNICAL SKILLS:', '', 'Experience (4 Years):', '', '', 'CERTIFICATION:', 'Completed 3 Months training on Oracle Apps Technical Training covered Core Java, Oracle Form & Reports, OAF, ADF from AlmaMate Training Institute, Noida.', 'ISTQB Foundation Level Certified.', '', 'PROJECT EXPERIENCE', 'Project (iAware):', 'Project Name: iAware (Integrated Analytics and Warehousing)', 'Role                   Senior Software Engineer', 'Duration           Jan 2017 to till date', 'Tools   :             Teradata, ODL Hive', '', 'Description:', 'The main objective of this project is to load the data that contain the details of clinical operation into the iAware Operational Data Warehouse (ODW) from ODL source after transforming the data as per the requirements provided.', 'Roles and Responsibilities:', 'Performing manual testing by performing the operations mentioned in the design steps. Compared the expected results with the actual outcome and recorded the results. Execute test cases on HP ALM', 'Co-coordinating with counterparts in understanding/gathering requirements & resolving queries.', 'Responsible for creating complete test Scenarios, test data, and reporting status ensuring accurate coverage of requirements and business processes. ', 'Defect management, Requirement analysis', 'Collaborating with the developers and discussing over the requirements and defects', 'Test Estimation Involved in the calls with Developers as well as BA for information gathering. ', 'Identify risks and provide mitigation plan. Escalate issues on timely manner to management.', 'Verified the data in target database by ETL process. ', 'Verified column mapping between source and target', '', 'Project (STRATEGIC DATA STORE):', 'Project Name: STRATEGIC DATA STORE', 'Role                   Senior Software Engineer', 'Duration           Nov 2015 to Jan 2017', 'Tools   :             SQL Server, QC', '', 'Description:', 'This is project from insurance domain, where we are creating a data warehouse for the client i.e. WILLIS.', '(World’s 2nd largest insurance broker).Here we are fetching the client data from different structured and unstructured source to the universal data model. This project is in the initial phase and currently we are moving the data from a single structured source. Here we are having 3 data layers Staging, Retention and Data store. From source to staging we do truncate load and for other layers we do incremental load.', '', 'Roles and Responsibilities:', 'I am working as a Senior ETL tester validating Extract, Transform and load process in the project.', 'Involved in testing after execution of packages for validating the technical as well as functional accuracy in the packages.', 'Identified Functional requirement and prepared the SQL scripts based on business requirements.', 'Analysis of Business Requirement, Test Cases and Defect Tracking.', 'Used macro for overall Schema verification of the Database.', '', 'Project (MS Dynamics): ', 'Project Name: MS Dynamics', 'Role: Software Engineer', 'Duration: Oct 2014 to Nov 2015', 'Tools   :  Jira', '', 'Description: In this project we were migrating Dynamic CRM 2016 to MS Dynamic CRM365 for the 39 Countries for BAYER client.', 'Roles and Responsibilities:', 'I was working as Tester for the project.', 'Involve in I-Pad Testing ,Mobile Application Testing  and CRM Based web Application, Raised Defects for the same', 'I have created test cases and executed the same.', 'Daily Status Reporting and Weekly Status Reporting to the Customer and Senior Management.', 'Timely Presentations and knowledge transfer to junior team member.', '', 'Education:', 'Bachelor of Technology (IT) from DIT School of Engineering, Greater Noida. GBTU University, Lucknow (2009- 2013) (64%).', 'Personal Details:', '', 'I hereby declare that the above mentioned information is correct up to my knowledge and I bear the responsibility for the correctness of the above mentioned particulars.', '                                                                                                                                                                                                        Shashi Singh                                                                                                                                                                     '], ['Chirag Dhoot', 'Phone\\t: +91 9768089671', 'Email\\t: chiragdhoot020@gmail.com', 'Address: 208/B, Amar Villa, Near Ashirwad hospital, Jesal Park, Bhayander - East, Mumbai: 401105', '', 'Summary:', 'Total 2.10 years of IT extensive experience as a Senior Software Tester with hands on experience performing Manual Testing using various different industry leading tools on various operating systems and platforms. A Software Quality Assurance professional in testing both in Client & Web based application and Windows environment. ', '', 'Skills:', '2.10 Years of experience with Agile or waterfall development methodology.', 'Worked with on-site and off-shore resources and supported UAT testing.', 'Good working knowledge on Insurance Domain.', 'Experienced in design and execution of Test Cases.', 'Excellent problem solving skills and good interpersonal skills.', 'Imparting practical training to new team members on the Product\\\\Application.', 'Experience in Functional Testing, Integration Testing, Web Service testing, Regression Testing, system testing, End to End testing, UAT and Defect Management.', 'Good experience in reproduction of problems & Generation of bug report.', 'Experienced with reporting and tracking Defects and interacting with the development team in correcting the defects. ', 'Analyzing User requirements, identifying scenarios and developing test cases.', 'Having a Basic Knowledge of Selenium Tool.', 'Honored with PAT on the Back Award for Best Tester for First Quarter 2015.', 'Received Best Project Delivery Appreciation For MetLife Colombia.', 'Highlighting Risks and Providing Solutions for Risks.', '', 'Core Technical Skills:', '', '', 'Employment History:', '', '', 'Professional Experience:', '', '', '', '', 'Awards:', '', 'POB- Pat on the Back Award for Best Tester for First Quarter 2015. ', 'Received Best Project Delivery Appreciation for MetLife GSP Columbia.', 'Certificate for Basic First Responder Training, Held by Municipal Corp. of Greater Mumbai.  ', 'Certificate for Mukt Samwad- 2013, Held by NMIMS Global Access for Continuing Education.', 'Certificates for Other Software Testing Courses from IGATE.', '', 'Educations details:', '', 'Bachelor of Science in Information Technology from Mumbai University with 71.00%', 'HSC from Maharashtra state board in 2011 with 69.41%.', 'SSC from Maharashtra state board in 2009 with 81.38 %.', '', '\\n', 'Personal Details:', '', 'Date of Birth\\t\\t: \\t02nd Jan 1993', 'Nationality \\t\\t: \\tIndian', 'Sex\\t\\t\\t: \\tMale', 'Marital Status\\t\\t: \\tSingle', 'Religion\\t\\t: \\tHindu', 'Mother Tongue\\t              : \\tHindi', 'Languages Known\\t: \\tEnglish, Hindi, Marwadi.', 'Hobbies\\t\\t: \\tCricket, Football, Computer Games & Music.', 'Last College Attended.  :\\tUsha Pravin Gandhi College of Management Studies', 'Stream\\t\\t\\t:\\tI.T.', 'Degree\\t\\t\\t: \\tB.Sc.I.T', 'Current Employer\\t:\\tCapgemini', 'Notice Period\\t\\t:\\t3 Months', 'Current Location             :             Airoli ( Navi Mumbai )', 'Domain Experience        :             Insurance', 'Current CTC                     :             3.15 Lakhs p.a ( 3.08L - Fixed )', 'Expected CTC                  :             5.50 Lakhs p.a + Variable', 'I hereby declare that the above mentioned details are true to the best of my knowledge and belief.', '', 'Chirag Dhoot', '8433528262', ''], ['Chirag Dhoot', 'Phone\\t: +91 9768089671', 'Email\\t: chiragdhoot020@gmail.com', 'Address: 208/B, Amar Villa, Near Ashirwad hospital, Jesal Park, Bhayander - East, Mumbai: 401105', '', 'Summary:', 'Total 2.10 years of IT extensive experience as a Senior Software Tester with hands on experience performing Manual Testing using various different industry leading tools on various operating systems and platforms. A Software Quality Assurance professional in testing both in Client & Web based application and Windows environment. ', '', 'Skills:', '2.10 Years of experience with Agile or waterfall development methodology.', 'Worked with on-site and off-shore resources and supported UAT testing.', 'Good working knowledge on Insurance Domain.', 'Experienced in design and execution of Test Cases.', 'Excellent problem solving skills and good interpersonal skills.', 'Imparting practical training to new team members on the Product\\\\Application.', 'Experience in Functional Testing, Integration Testing, Web Service testing, Regression Testing, system testing, End to End testing, UAT and Defect Management.', 'Good experience in reproduction of problems & Generation of bug report.', 'Experienced with reporting and tracking Defects and interacting with the development team in correcting the defects. ', 'Analyzing User requirements, identifying scenarios and developing test cases.', 'Having a Basic Knowledge of Selenium Tool.', 'Honored with PAT on the Back Award for Best Tester for First Quarter 2015.', 'Received Best Project Delivery Appreciation For MetLife Colombia.', 'Highlighting Risks and Providing Solutions for Risks.', '', 'Core Technical Skills:', '', '', 'Employment History:', '', '', 'Professional Experience:', '', '', '', '', 'Awards:', '', 'POB- Pat on the Back Award for Best Tester for First Quarter 2015. ', 'Received Best Project Delivery Appreciation for MetLife GSP Columbia.', 'Certificate for Basic First Responder Training, Held by Municipal Corp. of Greater Mumbai.  ', 'Certificate for Mukt Samwad- 2013, Held by NMIMS Global Access for Continuing Education.', 'Certificates for Other Software Testing Courses from IGATE.', '', 'Educations details:', '', 'Bachelor of Science in Information Technology from Mumbai University with 71.00%', 'HSC from Maharashtra state board in 2011 with 69.41%.', 'SSC from Maharashtra state board in 2009 with 81.38 %.', '', '\\n', 'Personal Details:', '', 'Date of Birth\\t\\t: \\t02nd Jan 1993', 'Nationality \\t\\t: \\tIndian', 'Sex\\t\\t\\t: \\tMale', 'Marital Status\\t\\t: \\tSingle', 'Religion\\t\\t: \\tHindu', 'Mother Tongue\\t              : \\tHindi', 'Languages Known\\t: \\tEnglish, Hindi, Marwadi.', 'Hobbies\\t\\t: \\tCricket, Football, Computer Games & Music.', 'Last College Attended.  :\\tUsha Pravin Gandhi College of Management Studies', 'Stream\\t\\t\\t:\\tI.T.', 'Degree\\t\\t\\t: \\tB.Sc.I.T', 'Current Employer\\t:\\tCapgemini', 'Notice Period\\t\\t:\\t3 Months', 'Current Location             :             Airoli ( Navi Mumbai )', 'Domain Experience        :             Insurance', 'Current CTC                     :             3.15 Lakhs p.a ( 3.08L - Fixed )', 'Expected CTC                  :             5.50 Lakhs p.a + Variable', 'I hereby declare that the above mentioned details are true to the best of my knowledge and belief.', '', 'Chirag Dhoot', '8433528262', '']]\n"
     ]
    }
   ],
   "source": [
    "import docx\n",
    "files_path = \"C:/Users/NEW/Desktop/Udemy/Resume\"\n",
    "read_files = glob.glob(os.path.join(files_path,\"*.docx\"))\n",
    "np_array_value =[]\n",
    "for path in read_files:\n",
    "    d=docx.Document(path)\n",
    "    dir(d)\n",
    "    texts=[p.text for p in d.paragraphs]\n",
    " #       np_array_value.append(texts)\n",
    "    np_array_value.append(texts)\n",
    "print(np_array_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 85, 152, 51, 87, 74, 74]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lens(listoflists):\n",
    "  return [len(x) for x in listoflists]\n",
    "lens(np_array_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8b3cf30fcecc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtexts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparagraphs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m  \u001b[1;31m#       np_array_value.append(texts)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mnp_array_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp_array_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "import docx\n",
    "files_path = \"C:/Users/NEW/Desktop/Udemy/Resume\"\n",
    "read_files = glob.glob(os.path.join(files_path,\"*.docx\"))\n",
    "np_array_value =[]\n",
    "for path in read_files:\n",
    "    d=docx.Document(path)\n",
    "    dir(d)\n",
    "    texts=[p.text for p in d.paragraphs]\n",
    " #       np_array_value.append(texts)\n",
    "    np_array_value.append(res)\n",
    "print(np_array_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = [sub.split() for subl in np_array_value for sub in subl]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docx2txt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6cf2608772b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnp_array_value\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mread_files\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mresume_data\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mdocx2txt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mnp_array_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresume_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'docx2txt' is not defined"
     ]
    }
   ],
   "source": [
    "np_array_value =[]\n",
    "for file in read_files:\n",
    "    resume_data =  docx2txt.process(read_files)\n",
    "    np_array_values.append(resume_data)\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chirag Dhoot\n",
      "\n",
      "Chirag Dhoot\n",
      "\n",
      "Phone\t: +91 9768089671\n",
      "\n",
      "Email\t: chiragdhoot020@gmail.com\n",
      "\n",
      "Address: 208/B, Amar Villa, Near Ashirwad hospital, Jesal Park, Bhayander - East, Mumbai: 401105\n",
      "\n",
      "\n",
      "\n",
      "Summary:\n",
      "\n",
      "\tTotal 2.10 years of IT extensive experience as a Senior Software Tester with hands on experience performing Manual Testing using various different industry leading tools on various operating systems and platforms. A Software Quality Assurance professional in testing both in Client & Web based application and Windows environment. \n",
      "\n",
      "\n",
      "\n",
      "Skills:\n",
      "\n",
      "2.10 Years of experience with Agile or waterfall development methodology.\n",
      "\n",
      "Worked with on-site and off-shore resources and supported UAT testing.\n",
      "\n",
      "Good working knowledge on Insurance Domain.\n",
      "\n",
      "Experienced in design and execution of Test Cases.\n",
      "\n",
      "Excellent problem solving skills and good interpersonal skills.\n",
      "\n",
      "Imparting practical training to new team members on the Product\\Application.\n",
      "\n",
      "Experience in Functional Testing, Integration Testing, Web Service testing, Regression Testing, system testing, End to End testing, UAT and Defect Management.\n",
      "\n",
      "Good experience in reproduction of problems & Generation of bug report.\n",
      "\n",
      "Experienced with reporting and tracking Defects and interacting with the development team in correcting the defects. \n",
      "\n",
      "Analyzing User requirements, identifying scenarios and developing test cases.\n",
      "\n",
      "Having a Basic Knowledge of Selenium Tool.\n",
      "\n",
      "Honored with PAT on the Back Award for Best Tester for First Quarter 2015.\n",
      "\n",
      "Received Best Project Delivery Appreciation For MetLife Colombia.\n",
      "\n",
      "Highlighting Risks and Providing Solutions for Risks.\n",
      "\n",
      "\n",
      "\n",
      "Core Technical Skills:\n",
      "\n",
      "\n",
      "\n",
      "Software Testing Skills\n",
      "\n",
      "Manual, Web testing, Functional, Regression, Ad hoc Testing, Mobile Testing, UI and Compatibility Testing, User Acceptance Testing, Test life cycle, SDLC, Agile Testing, Document testing, Test case design, Test cases execution, Defect life cycle, Defect tracking.\n",
      "\n",
      "Operating Systems\n",
      "\n",
      "Windows XP/Vista/7/10\n",
      "\n",
      "Defect Tracking Tool\n",
      "\n",
      "HP-QC, Bugzilla\n",
      "\n",
      "Other Tools\t\n",
      "\n",
      "Jmeter, Microsoft Excel,Microsoft Office Tools, Firebug, Fiddler, Postman\n",
      "\n",
      "SQL\n",
      "\n",
      "Basic Knowledge of SQL\n",
      "\n",
      "Methodologies\n",
      "\n",
      "Agile- Scrum, Waterfall\n",
      "\n",
      "\n",
      "\n",
      "Employment History:\n",
      "\n",
      "\t\tCurrent\n",
      "\n",
      "\t\tCapgemini\n",
      "\n",
      "\t\tPeriod\n",
      "\n",
      "\t\t31st July 2014 till Present\n",
      "\n",
      "\t\tDesignation\n",
      "\n",
      "\t\tSoftware Engineer\n",
      "\n",
      "\t\tClient Side\n",
      "\n",
      "\t\tWillis Towers Watson (Sydney, Australia ), MetLife ( USA, Colombia )\n",
      "\n",
      "\t\tRole\n",
      "\n",
      "\t\tManual Tester\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Professional Experience:\n",
      "\n",
      "\n",
      "\n",
      "\t\tCompany\n",
      "\n",
      "Capgemini\n",
      "\n",
      "\t\tProject\n",
      "\n",
      "Willis Towers Watson – Online Questionnaire\n",
      "\n",
      "\t\tPeriod\n",
      "\n",
      "1st January 2016 to Present\n",
      "\n",
      "\t\tRole\n",
      "\n",
      "\t\tSoftware Test Engineer\n",
      "\n",
      "Participation in Business requirements review meetings and identification of key scenarios for functionality, behavioral and UI testing\n",
      "\n",
      "Analyzing User requirements, identifying scenarios and developing test cases.\n",
      "\n",
      "Discussion of stories/Scenarios with product owner and UAT.\n",
      "\n",
      "Participating in daily standup calls/Testing Catch up call for Testing updates.\n",
      "\n",
      "Participated in all the Scrum events such as Sprint Planning, Daily Stand up call, Sprint review and sprint retrospective\n",
      "\n",
      "Summarized issues, reporting defects and tracking the bugs using QC and MTM till they get delivered on live environment.\n",
      "\n",
      "Project Description\n",
      "\n",
      "Willis OQ is online Questionnaire which provides user with ability to perform the office tools Microsoft word and Microsoft excel operations in a web based Application.\n",
      "\n",
      "\n",
      "\n",
      "\t\tCompany\n",
      "\n",
      "Capgemini\n",
      "\n",
      "\t\tProject\n",
      "\n",
      "\t\tGSP Colombia MetLife – Global Sales Platform\n",
      "\n",
      "\t\tPeriod\n",
      "\n",
      "27th February 2015 to 31st December 2015\n",
      "\n",
      "\t\tRole\n",
      "\n",
      "\t\tSoftware Test Engineer\n",
      "\n",
      "Participation in Business requirements review meetings and identification of key scenarios for functionality, behavioral and UI testing.\n",
      "\n",
      "Analyzing User requirements, identifying scenarios and developing test cases.\n",
      "\n",
      "Discussion of stories/Scenarios with product owner and UAT.\n",
      "\n",
      "Participating in daily standup calls/Testing Catch up call for Testing updates.\n",
      "\n",
      "Participated in all the Scrum events such as Sprint Planning, Daily Stand up call, Sprint review and sprint retrospective\n",
      "\n",
      "Summarized issues, reporting defects and tracking the bugs using QC and MTM till they get delivered on live environment. \n",
      "\n",
      "Project Description\n",
      "\n",
      "GSP Columbia allows an admin to configure plans & sells quotes to their clients through application, agents and they can manage the sales of the various insurance products.\n",
      "\n",
      "\n",
      "\n",
      "\t\tCompany\n",
      "\n",
      "\t\tCapgemini\n",
      "\n",
      "\t\tClient\n",
      "\n",
      "\t\tMetLife ( USA )\n",
      "\n",
      "\t\tProject\n",
      "\n",
      "GSP Core MetLife – Global Sales Platform\n",
      "\n",
      "\t\tPeriod\n",
      "\n",
      "31st October 2014 to 26th February 2015\n",
      "\n",
      "\t\tRole\n",
      "\n",
      "\t\tSoftware Test Engineer\n",
      "\n",
      "Participation in Business requirements review meetings and identification of key  scenarios for functionality, behavioral and UI testing\n",
      "\n",
      "Analyzing User requirements, identifying scenarios and developing test cases.\n",
      "\n",
      "Discussion of stories/Scenarios with product owner and UAT.\n",
      "\n",
      "Worked as an Onsite Coordinator during Onsite tenure in Bupa at UK.\n",
      "\n",
      "Worked with on-site and off-shore resources and supported UAT testing\n",
      "\n",
      "Participating in daily standup calls/Testing Catch up call for Testing updates.\n",
      "\n",
      "Participated in all the Scrum events such as Sprint Planning, Daily Stand up call, Sprint  review and sprint retrospective\n",
      "\n",
      "Summarized issues, reporting defects and tracking the bugs using QC and MTM till they get delivered on live environment. \n",
      "\n",
      "\t\tProject Description\n",
      "\n",
      "GSP Core is software platform for sale of Life insurance products that will be configurable to allow support of various simple products and ensuring consistent user experience. Project scope was to develop GSP Core Products and regional implementation of Products. \n",
      "\n",
      "\n",
      "\n",
      "Awards:\n",
      "\n",
      "\n",
      "\n",
      "POB- Pat on the Back Award for Best Tester for First Quarter 2015. \n",
      "\n",
      "Received Best Project Delivery Appreciation for MetLife GSP Columbia.\n",
      "\n",
      "Certificate for Basic First Responder Training, Held by Municipal Corp. of Greater Mumbai.  \n",
      "\n",
      "Certificate for Mukt Samwad- 2013, Held by NMIMS Global Access for Continuing Education.\n",
      "\n",
      "Certificates for Other Software Testing Courses from IGATE.\n",
      "\n",
      "\n",
      "\n",
      "Educations details:\n",
      "\n",
      "\n",
      "\n",
      "Bachelor of Science in Information Technology from Mumbai University with 71.00%\n",
      "\n",
      "HSC from Maharashtra state board in 2011 with 69.41%.\n",
      "\n",
      "SSC from Maharashtra state board in 2009 with 81.38 %.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Personal Details:\n",
      "\n",
      "\n",
      "\n",
      "Date of Birth\t\t: \t02nd Jan 1993\n",
      "\n",
      "Nationality \t\t: \tIndian\n",
      "\n",
      "Sex\t\t\t: \tMale\n",
      "\n",
      "Marital Status\t\t: \tSingle\n",
      "\n",
      "Religion\t\t: \tHindu\n",
      "\n",
      "Mother Tongue\t              : \tHindi\n",
      "\n",
      "Languages Known\t: \tEnglish, Hindi, Marwadi.\n",
      "\n",
      "Hobbies\t\t: \tCricket, Football, Computer Games & Music.\n",
      "\n",
      "Last College Attended.  :\tUsha Pravin Gandhi College of Management Studies\n",
      "\n",
      "Stream\t\t\t:\tI.T.\n",
      "\n",
      "Degree\t\t\t: \tB.Sc.I.T\n",
      "\n",
      "Current Employer\t:\tCapgemini\n",
      "\n",
      "Notice Period\t\t:\t3 Months\n",
      "\n",
      "Current Location             :             Airoli ( Navi Mumbai )\n",
      "\n",
      "Domain Experience        :             Insurance\n",
      "\n",
      "Current CTC                     :             3.15 Lakhs p.a ( 3.08L - Fixed )\n",
      "\n",
      "Expected CTC                  :             5.50 Lakhs p.a + Variable\n",
      "\n",
      "I hereby declare that the above mentioned details are true to the best of my knowledge and belief.\n",
      "\n",
      "\n",
      "\n",
      "Chirag Dhoot\n",
      "\n",
      "8433528262\n",
      "\n",
      "\n",
      "\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import docx2txt\n",
    " \n",
    "# read in word file\n",
    "result = docx2txt.process(\"C:/Users/NEW/Desktop/Udemy/Resume/Resume_Ch_June.docx\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R E S U M E\n",
      "\n",
      "DIVYA SHARma\n",
      "SUMMARY\n",
      "\n",
      "Work Experience\n",
      "academics\n",
      "\n",
      "SKILLS\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Company: IBM India Pvt Ltd\n",
      "PROJECT DETAILS \n",
      "\n",
      "Project 1 : DLG Emerald Integration\n",
      "Client: Direct Line Group Insurance, UK\n",
      "Duration: Sep’14 to Oct’16.\n",
      "Technology: Mule ESB \n",
      "\n",
      "Environment: AnyPoint Studio, Mule Studio, Soap UI, SVN, JAVA.\n",
      "Project Overview:  The intent of this project is to develop middleware services for DLG using Mule, JMS, and Oracle DB which will be used to bridge DLG GW Systems & Third Party services. \n",
      "Roles and Responsibilities: \n",
      "\n",
      "Responsible for being in the project team in delivering solution to our customer in the\n",
      " Insurance Sector.\n",
      "Deliver new and complex high quality solutions to clients in response to varying business requirements.\n",
      "Responsible for effective communication between the project team and the customer.\n",
      "\n",
      "Project 2 : Sprint Account\n",
      "Client: Sprint Telecommunications, US\n",
      "Duration: Nov’16 to till date.\n",
      "Technology: Mule ESB \n",
      "\n",
      "Environment: AnyPoint Studio, Mule Studio, Soap UI, SVN, JAVA, RAML\n",
      "Project Overview:  The intent of this project is to develop REST API using RAML and calling Third Party services.\n",
      "Roles and Responsibilities: \n",
      "\n",
      "Responsible for developing API using RAML to the customer in Telecom Sector.\n",
      "Coding, unit testing the components, functional testing.\n",
      "Delivering the code with high standards, quality and delivered it with in the time lines.\n",
      "\n",
      "\n",
      "CERTIFICATION\n",
      "\n",
      "Certified as MCD Integration and API Associate.(Mule 3.7) with 91.25%\n",
      "\n",
      "PERSONAL DETAILS:\n",
      "\t\t\t\t\t\t\tSignature\n"
     ]
    }
   ],
   "source": [
    "import docx\n",
    " \n",
    "# open connection to Word Document\n",
    "\n",
    "doc = docx.Document('C:/Users/NEW/Desktop/Udemy/Resume/Divya_Resume.docx')\n",
    "for para in doc.paragraphs: \n",
    "    print(para.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<docx.document.Document object at 0x0000020EE17B85A0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R E S U M E',\n",
       " '',\n",
       " 'DIVYA SHARma',\n",
       " 'SUMMARY',\n",
       " '',\n",
       " 'Work Experience',\n",
       " 'academics',\n",
       " '',\n",
       " 'SKILLS',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Company: IBM India Pvt Ltd',\n",
       " 'PROJECT DETAILS ',\n",
       " '',\n",
       " 'Project 1 : DLG Emerald Integration',\n",
       " 'Client: Direct Line Group Insurance, UK',\n",
       " 'Duration: Sep’14 to Oct’16.',\n",
       " 'Technology: Mule ESB ',\n",
       " '',\n",
       " 'Environment: AnyPoint Studio, Mule Studio, Soap UI, SVN, JAVA.',\n",
       " 'Project Overview:  The intent of this project is to develop middleware services for DLG using Mule, JMS, and Oracle DB which will be used to bridge DLG GW Systems & Third Party services.\\xa0',\n",
       " 'Roles and Responsibilities: ',\n",
       " '',\n",
       " 'Responsible for being in the project team in delivering solution to our customer in the',\n",
       " ' Insurance Sector.',\n",
       " 'Deliver new and complex high quality solutions to clients in response to varying business requirements.',\n",
       " 'Responsible for effective communication between the project team and the customer.',\n",
       " '',\n",
       " 'Project 2 : Sprint Account',\n",
       " 'Client: Sprint Telecommunications, US',\n",
       " 'Duration: Nov’16 to till date.',\n",
       " 'Technology: Mule ESB ',\n",
       " '',\n",
       " 'Environment: AnyPoint Studio, Mule Studio, Soap UI, SVN, JAVA, RAML',\n",
       " 'Project Overview:  The intent of this project is to develop REST API using RAML and calling Third Party services.',\n",
       " 'Roles and Responsibilities: ',\n",
       " '',\n",
       " 'Responsible for developing API using RAML to the customer in Telecom Sector.',\n",
       " 'Coding, unit testing the components, functional testing.',\n",
       " 'Delivering the code with high standards, quality and delivered it with in the time lines.',\n",
       " '',\n",
       " '',\n",
       " 'CERTIFICATION',\n",
       " '',\n",
       " 'Certified as MCD Integration and API Associate.(Mule 3.7) with 91.25%',\n",
       " '',\n",
       " 'PERSONAL DETAILS:',\n",
       " '\\t\\t\\t\\t\\t\\t\\tSignature']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import docx\n",
    "d=docx.Document('C:/Users/NEW/Desktop/Udemy/Resume/Divya_Resume.docx')\n",
    "dir(d)\n",
    "texts=[p.text for p in d.paragraphs]\n",
    "texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tristram Lansdowne - Curriculum VitaeBorn 1983Education:2007:   Bachelor of Fine Arts, Ontario College of Art and DesignSolo Exhibitions:2012 Fata Morgana Œ LE Gallery, Toronto\n",
      "2010 Refuge - \n",
      "Joshua Liner Gallery, New York\n",
      "2010 Archimancy - \n",
      "LE Gallery, Toronto\n",
      "2009 Entropical Paradise - \n",
      "LE Gallery, Toronto\n",
      "2008 Structural Integrity - \n",
      "LE Gallery, Toronto\n",
      "2007 Beautiful Decay - \n",
      "Winchester Galleries, Victoria, B.C.Group Exhibitions:2012 Ecotopia - Kitchener-Waterloo Art Gallery; Southern Alberta Art Gallery\n",
      "2012 Space/Form Œ Breeze Block Gallery, Portland\n",
      "\n",
      "2012 Death and the City Œ LE Gallery, Toronto\n",
      "\n",
      "2012 60 Painters - Humber College School of Arts and Media, Etobicoke\n",
      "\n",
      "2011 RBC Painting Competition Finalist Exhibition - \n",
      "Art Gallery of Alberta, Edmonton; Art Gallery of Hamilton;  \n",
      "Powerplant, Toronto\n",
      "2011 Hanged & Drawn - \n",
      "LE Gallery, Toronto\n",
      "2011 Contained - \n",
      "Boston Centre for the Arts, Boston\n",
      "2011 Merge - \n",
      "Art Gallery of Ontario Art Rentals Gallery, Toronto\n",
      "2010 Empire of Dreams: Phenomenology of the built environment\n",
      " - Museum of Contemporary Canadian Art, Toronto2009   Who™s Got the Paper™s -\n",
      " LE Gallery, Toronto2009 Summer Group Show -\n",
      " Joshua Liner Gallery, New York\n",
      "2009 LE Cinq: 5\n",
      "th Year Anniversary Exhibition - LE Gallery, Toronto2007   Young Romantics - \n",
      "Gallery 1313, TorontoGrants & Awards: 2013: Toronto Arts Council project grant\n",
      " Ontario Arts Council project grant\n",
      "\n",
      " Canada Council for the Arts project grant\n",
      "\n",
      "2011: Ontario Arts Council project grant\n",
      "\n",
      "2007:   Canadian Society of Painters in Water Colour:  Julius Gri˜th Award\n",
      "Collections:2013: National Gallery of Canada\n",
      "2013: MicrosoftBibliography: \"Death and the City.\" Pilot Magazine Issue X, 2012\n",
      "Mould Map II.  Land˚ll Editions, 2011.  Ed Hugh Frost & Leon Sadler\n",
      "Boon, Trish. ﬁLike Milk and Blood.ﬂ  Square2 Issue 4,  April 2011\n",
      "Liss, David.  Museum of Contemporary Canadian Art & One Hour Empire - Empire of Dreams Catalogue 2010\n",
      "Lechner, Alysa.  ﬁBeauty in the Breakdown.ﬂ  Ion Magazine Issue 64, April 2010\n",
      "Sandals, Leah. ﬁAt the galleries.ﬂ National Post, December 2nd 2010 Dault, Gary Michael. ﬁA convincing replication of reality and its layers.ﬂ The Globe and Mail, December 12th 2009\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'D:/NLP_Resume/resume/template_new.csv' does not exist: b'D:/NLP_Resume/resume/template_new.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-12f861262f31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0monlyfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0monlyfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m     \u001b[0mdat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_profile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m     \u001b[0mfinal_database\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_database\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-12f861262f31>\u001b[0m in \u001b[0;36mcreate_profile\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m#below is the csv where we have all the keywords, you can customize your own\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mkeyword_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:/NLP_Resume/resume/template_new.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[0mstats_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeyword_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Statistics'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mNLP_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeyword_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NLP'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'D:/NLP_Resume/resume/template_new.csv' does not exist: b'D:/NLP_Resume/resume/template_new.csv'"
     ]
    }
   ],
   "source": [
    "#Resume Phrase Matcher code\n",
    "\n",
    "\n",
    "#importing all required libraries\n",
    "\n",
    "import PyPDF2\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "#Function to read resumes from the folder one by one\n",
    "mypath='C:/Users/NEW/Desktop/Udemy/Resume/python' #enter your path here where you saved the resumes\n",
    "onlyfiles = [os.path.join(mypath, f) for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath, f))]\n",
    "\n",
    "def pdfextract(file):\n",
    "    fileReader = PyPDF2.PdfFileReader(open(file,'rb'))\n",
    "    countpage = fileReader.getNumPages()\n",
    "    count = 0\n",
    "    text = []\n",
    "    while count < countpage:    \n",
    "        pageObj = fileReader.getPage(count)\n",
    "        count +=1\n",
    "        t = pageObj.extractText()\n",
    "        print (t)\n",
    "        text.append(t)\n",
    "    return text\n",
    "\n",
    "#function to read resume ends\n",
    "\n",
    "\n",
    "#function that does phrase matching and builds a candidate profile\n",
    "def create_profile(file):\n",
    "    text = pdfextract(file) \n",
    "    text = str(text)\n",
    "    text = text.replace(\"\\\\n\", \"\")\n",
    "    text = text.lower()\n",
    "    #below is the csv where we have all the keywords, you can customize your own\n",
    "    keyword_dict = pd.read_csv('D:/NLP_Resume/resume/template_new.csv')\n",
    "    stats_words = [nlp(text) for text in keyword_dict['Statistics'].dropna(axis = 0)]\n",
    "    NLP_words = [nlp(text) for text in keyword_dict['NLP'].dropna(axis = 0)]\n",
    "    ML_words = [nlp(text) for text in keyword_dict['Machine Learning'].dropna(axis = 0)]\n",
    "    DL_words = [nlp(text) for text in keyword_dict['Deep Learning'].dropna(axis = 0)]\n",
    "    R_words = [nlp(text) for text in keyword_dict['R Language'].dropna(axis = 0)]\n",
    "    python_words = [nlp(text) for text in keyword_dict['Python Language'].dropna(axis = 0)]\n",
    "    Data_Engineering_words = [nlp(text) for text in keyword_dict['Data Engineering'].dropna(axis = 0)]\n",
    "\n",
    "    matcher = PhraseMatcher(nlp.vocab)\n",
    "    matcher.add('Stats', None, *stats_words)\n",
    "    matcher.add('NLP', None, *NLP_words)\n",
    "    matcher.add('ML', None, *ML_words)\n",
    "    matcher.add('DL', None, *DL_words)\n",
    "    matcher.add('R', None, *R_words)\n",
    "    matcher.add('Python', None, *python_words)\n",
    "    matcher.add('DE', None, *Data_Engineering_words)\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    d = []  \n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        rule_id = nlp.vocab.strings[match_id]  # get the unicode ID, i.e. 'COLOR'\n",
    "        span = doc[start : end]  # get the matched slice of the doc\n",
    "        d.append((rule_id, span.text))      \n",
    "    keywords = \"\\n\".join(f'{i[0]} {i[1]} ({j})' for i,j in Counter(d).items())\n",
    "    \n",
    "    ## convertimg string of keywords to dataframe\n",
    "    df = pd.read_csv(StringIO(keywords),names = ['Keywords_List'])\n",
    "    df1 = pd.DataFrame(df.Keywords_List.str.split(' ',1).tolist(),columns = ['Subject','Keyword'])\n",
    "    df2 = pd.DataFrame(df1.Keyword.str.split('(',1).tolist(),columns = ['Keyword', 'Count'])\n",
    "    df3 = pd.concat([df1['Subject'],df2['Keyword'], df2['Count']], axis =1) \n",
    "    df3['Count'] = df3['Count'].apply(lambda x: x.rstrip(\")\"))\n",
    "    \n",
    "    base = os.path.basename(file)\n",
    "    filename = os.path.splitext(base)[0]\n",
    "       \n",
    "    name = filename.split('_')\n",
    "    name2 = name[0]\n",
    "    name2 = name2.lower()\n",
    "    ## converting str to dataframe\n",
    "    name3 = pd.read_csv(StringIO(name2),names = ['Candidate Name'])\n",
    "    \n",
    "    dataf = pd.concat([name3['Candidate Name'], df3['Subject'], df3['Keyword'], df3['Count']], axis = 1)\n",
    "    dataf['Candidate Name'].fillna(dataf['Candidate Name'].iloc[0], inplace = True)\n",
    "\n",
    "    return(dataf)\n",
    "        \n",
    "#function ends\n",
    "        \n",
    "#code to execute/call the above functions\n",
    "\n",
    "final_database=pd.DataFrame()\n",
    "i = 0 \n",
    "while i < len(onlyfiles):\n",
    "    file = onlyfiles[i]\n",
    "    dat = create_profile(file)\n",
    "    final_database = final_database.append(dat)\n",
    "    i +=1\n",
    "    print(final_database)\n",
    "\n",
    "    \n",
    "#code to count words under each category and visulaize it through Matplotlib\n",
    "\n",
    "final_database2 = final_database['Keyword'].groupby([final_database['Candidate Name'], final_database['Subject']]).count().unstack()\n",
    "final_database2.reset_index(inplace = True)\n",
    "final_database2.fillna(0,inplace=True)\n",
    "new_data = final_database2.iloc[:,1:]\n",
    "new_data.index = final_database2['Candidate Name']\n",
    "#execute the below line if you want to see the candidate profile in a csv format\n",
    "#sample2=new_data.to_csv('sample.csv')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "ax = new_data.plot.barh(title=\"Resume keywords by category\", legend=False, figsize=(25,7), stacked=True)\n",
    "labels = []\n",
    "for j in new_data.columns:\n",
    "    for i in new_data.index:\n",
    "        label = str(j)+\": \" + str(new_data.loc[i][j])\n",
    "        labels.append(label)\n",
    "patches = ax.patches\n",
    "for label, rect in zip(labels, patches):\n",
    "    width = rect.get_width()\n",
    "    if width > 0:\n",
    "        x = rect.get_x()\n",
    "        y = rect.get_y()\n",
    "        height = rect.get_height()\n",
    "        ax.text(x + width/2., y + height/2., label, ha='center', va='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text pre-processing\n",
    "\"\"\"removes punctuation, stopwords, and returns a list of the remaining words, or tokens\"\"\"\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "import string\n",
    "def text_process(text):\n",
    "    '''\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Return the cleaned text as a list of words\n",
    "    4. Remove words\n",
    "    '''\n",
    "    stemmer = WordNetLemmatizer()\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join([i for i in nopunc if not i.isdigit()])\n",
    "    nopunc =  [word.lower() for word in nopunc.split() if word not in stopwords.words('english')]\n",
    "    return [stemmer.lemmatize(word) for word in nopunc]\n",
    "\n",
    "#testing the function with a sample text#\n",
    "sample_text = \"Hey There! This is a Sample review, which 123happens {blah}%456 to contain happened punctuations universal rights of right contained.\"\n",
    "print(text_process(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = [][]\n",
    "for item in np_array_value:\n",
    "    print(text_process(item))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "\n",
    "# List all subdirectories using scandir()\n",
    "basepath = 'C:/Users/NEW/Desktop/Udemy/Resume/dataset'\n",
    "with os.scandir(basepath) as entries:\n",
    "    for entry in entries:\n",
    "        if entry.is_dir():\n",
    "            print(entry.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "glob.glob('C:/Users/NEW/Desktop/Udemy/Resume/dataset/*.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Rejected\\\\MSBI\\\\Gitika_Mishra_4_5yr_Exp_MSBI_Developer.docx',\n",
       " 'Rejected\\\\MSBI\\\\Hemant_Nikam_MSBI.doc',\n",
       " 'Rejected\\\\MSBI\\\\Jeweel Roy.docx',\n",
       " 'Rejected\\\\MSBI\\\\Ravi Shankar.docx',\n",
       " 'Rejected\\\\MSBI\\\\Sahil_Kadarbhai_Resume.doc',\n",
       " 'Rejected\\\\MSBI\\\\Shruti Tembhurnikar.docx',\n",
       " 'Rejected\\\\MSBI\\\\Snehal Giri.docx',\n",
       " 'Rejected\\\\Rejected - Big Data Developer\\\\Anupam Gaur.doc',\n",
       " 'Rejected\\\\Rejected - Big Data Developer\\\\ArvindKumarThakur.doc',\n",
       " 'Rejected\\\\Rejected - Big Data Developer\\\\Ashwani Kumar.doc',\n",
       " 'Rejected\\\\Rejected - Big Data Developer\\\\Big Data Resume VineetGarg.pdf',\n",
       " 'Rejected\\\\Rejected - Big Data Developer\\\\Deepak Resume.doc',\n",
       " 'Rejected\\\\Rejected - Big Data Developer\\\\Kritika_Joshi_BigdataProfile.docx',\n",
       " 'Rejected\\\\Rejected - Big Data Developer\\\\Lokesh Gupta.docx',\n",
       " 'Rejected\\\\Rejected - Big Data Developer\\\\Mahesh Gupta.docx',\n",
       " 'Rejected\\\\Rejected - Big Data Developer\\\\Praveen Agrawal.docx',\n",
       " 'Rejected\\\\Rejected - Big Data Developer\\\\Rishi Raj.doc',\n",
       " 'Rejected\\\\Rejected - Big Data Developer\\\\Shubham Shukla.doc',\n",
       " 'Rejected\\\\Rejected - Big Data Developer\\\\Tarvinder Singh.docx',\n",
       " 'Rejected\\\\Rejected - Big Data Developer\\\\Ved Prakash.doc',\n",
       " 'Rejected\\\\Rejected - Project Management Office\\\\Ankita Sinha.docx',\n",
       " 'Rejected\\\\Rejected - Project Management Office\\\\Chakravarti Singh.pdf',\n",
       " 'Rejected\\\\Rejected - Project Management Office\\\\Hasanuzzaman.pdf',\n",
       " 'Rejected\\\\Rejected - Project Management Office\\\\Manish Atal.doc',\n",
       " 'Rejected\\\\Rejected - Project Management Office\\\\Prafulla_CV.pdf',\n",
       " 'Rejected\\\\Rejected - Project Management Office\\\\Priya Mahur.pdf',\n",
       " 'Rejected\\\\Rejected - Project Management Office\\\\Rejected - Project Management Office (1)\\\\Heena Prashar.pdf',\n",
       " 'Rejected\\\\Rejected - Project Management Office\\\\Rejected - Project Management Office (1)\\\\Manjari_Resume.doc',\n",
       " 'Rejected\\\\Rejected - Project Management Office\\\\Rejected - Project Management Office (1)\\\\PRITI SINGH.docx',\n",
       " 'Rejected\\\\Rejected - Project Management Office\\\\Rejected - Project Management Office (1)\\\\Rashi Sharma.docx',\n",
       " 'Rejected\\\\Rejected - Project Management Office\\\\Satabdi Sen.doc',\n",
       " 'Rejected\\\\Rejected - Project Management Office\\\\Shashikant Chauhan.docx',\n",
       " 'Rejected\\\\Rejected - Project Management Office\\\\Shruti Mishra.docx',\n",
       " 'Rejected\\\\Rejected - Project Management Office\\\\Sonu Singh Rana.docx',\n",
       " 'Rejected\\\\Rejected - Project Management Office\\\\Taru Sharma.doc',\n",
       " 'Rejected\\\\Rejected - Project Management Office\\\\Vikash Kumar Sharma.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Abhinav Kukreja.doc',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Aditya Agarwal.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Avneet Kumar.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Balpreet Kaur.pdf',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Deshant Digani.doc',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Devender Chamoli.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Inderbir Singh Matharu.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Mohit Chandra Saxena.pdf',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Mohit Manocha.doc',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Piyush Kalra.doc',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rahul Garg.doc',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected - SQL Server, BA, Investment Banking (1)\\\\Ankit Mittal.doc',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected - SQL Server, BA, Investment Banking (1)\\\\Ankur Gulati.pdf',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected - SQL Server, BA, Investment Banking (1)\\\\Ayush Goyal.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected - SQL Server, BA, Investment Banking (1)\\\\Deepak Sharma.pdf',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected - SQL Server, BA, Investment Banking (1)\\\\Divjyot Talwar.pdf',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected - SQL Server, BA, Investment Banking (1)\\\\Junaid Hakeem.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected - SQL Server, BA, Investment Banking (1)\\\\Laxman Rathore.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected - SQL Server, BA, Investment Banking (1)\\\\Mayank Parashar.pdf',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected - SQL Server, BA, Investment Banking (1)\\\\Nancy Sood.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected - SQL Server, BA, Investment Banking (1)\\\\Sandeep Kumar.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected - SQL Server, BA, Investment Banking (1)\\\\Saurabh Gupta.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected - SQL Server, BA, Investment Banking (1)\\\\Shailaj Kumar.pdf',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected - SQL Server, BA, Investment Banking (1)\\\\Varun Das.doc',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Abhishek Gupta.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Ankur Singh Kashyap.doc',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Anwesha Sengupta.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Ashish Marwah.doc',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Devender Dagar.doc',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Hitesh Puri.doc',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Jagwinder Singh.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Jeevan Gurpratap.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Jyoti Jindal.doc',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Ketan Aralkar.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Krishna Kishore Appala.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Kunal Sachdeva.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Kunal Sachdeva.pdf',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Lokesh Gupta.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Manish Kumar BA.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Manish Kumar.doc',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\ManojKumar.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Manoranjan Rajguru.doc',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Mukesh Kumar.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Nikhil Gupta.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Priyanshu.doc',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Profile - Jitendra Pratap.pdf',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Profile - Nishant Dubey.pdf',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Profile - Stuti Singh.doc',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Rahul Sharma.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Sahil Gupta.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Sheelabhadra Singhdeo.doc',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Shivam Goel.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Sudama Singh Thakur.doc',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Taru Gangal.pdf',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Rejected Profiles - SQL Server, BA, Investment Banking\\\\Yash Kumar Kaushik.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Sankalp Pandey.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Smridh Sahney.docx',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Sumit Gupta.doc',\n",
       " 'Rejected\\\\Rejected - SQL Server, BA, Investment Banking\\\\Yashika Srivastava.docx',\n",
       " 'Rejected\\\\Resume_ Neetu Kumari.docx',\n",
       " 'Rejected\\\\Resume_Pradeep.docx',\n",
       " 'Rejected\\\\T2S_Chirag Dhamija_2.6 years_Gurgaon.pdf',\n",
       " 'Rejected\\\\T2S_Gunmeetkumar_3.5 years_noida.doc',\n",
       " 'Rejected\\\\Tableau\\\\Anand Sahu.pdf',\n",
       " 'Rejected\\\\Tableau\\\\Arvind Salunkhe.docx',\n",
       " 'Rejected\\\\Tableau\\\\Jeevesh Rath.docx',\n",
       " 'Rejected\\\\Tableau\\\\MaheshGupta_15 yrs_Pune.doc',\n",
       " 'Rejected\\\\Tableau\\\\Parag Khatri.doc',\n",
       " 'Rejected\\\\Tableau\\\\Pavan Kumar CHVRN.DOC',\n",
       " 'Rejected\\\\Tableau\\\\Prashant Naik-11.8yrs-Tableau Architect-Pune.docx',\n",
       " 'Rejected\\\\Tableau\\\\Premnath R J-14yrs-Tableau Architect-Bangalore.doc',\n",
       " 'Rejected\\\\Tableau\\\\peeyush Gupta.doc',\n",
       " 'Selected\\\\MSBI\\\\Bibhudatta_Hotta_Resume.docx',\n",
       " 'Selected\\\\MSBI\\\\Bikash Singh.docx',\n",
       " 'Selected\\\\MSBI\\\\Shubham Garg.doc',\n",
       " 'Selected\\\\MSBI\\\\Sourabh Muchhal.docx',\n",
       " 'Selected\\\\MSBI\\\\VivekShilimkar.doc',\n",
       " 'Selected\\\\SHUBHAM AGRAWAL.doc',\n",
       " 'Selected\\\\Selected - Big Data Developer\\\\AVDHESH SACHDEVA.pdf',\n",
       " 'Selected\\\\Selected - Project Management Office\\\\Aditi Kathuria.doc',\n",
       " 'Selected\\\\Selected - Project Management Office\\\\Parul Batra.pdf',\n",
       " 'Selected\\\\Selected - SQL Server, BA, Investment Banking\\\\Gagandeep Singla.docx',\n",
       " 'Selected\\\\Selected - SQL Server, BA, Investment Banking\\\\Nidhi Khanna.docx',\n",
       " 'Selected\\\\Selected - SQL Server, BA, Investment Banking\\\\Pratibha Gupta.docx',\n",
       " 'Selected\\\\Selected - SQL Server, BA, Investment Banking\\\\Profile - Nishu Jain.docx',\n",
       " 'Selected\\\\Selected - SQL Server, BA, Investment Banking\\\\Saumya Agarwal.docx',\n",
       " 'Selected\\\\Selected - SQL Server, BA, Investment Banking\\\\Swapnil Dhamani.docx',\n",
       " 'Selected\\\\Tableau\\\\Madheswaran Sivalingam_16yrs_Chennai.docx',\n",
       " 'Selected\\\\Tableau\\\\Manish Amin.docx',\n",
       " 'Selected\\\\Tableau\\\\Mohammad Faizan.doc',\n",
       " 'Selected\\\\Tableau\\\\Vijay Kumar Ajarla-13yrs-Tableau Architect-Hyderabad.docx'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "root_dir = \"C:/Users/NEW/Desktop/Udemy/Resume/dataset\"\n",
    "file_set = set()\n",
    "\n",
    "for dir_, _, files in os.walk(root_dir):\n",
    "    for file_name in files:\n",
    "        rel_dir = os.path.relpath(dir_, root_dir)\n",
    "        rel_file = os.path.join(rel_dir, file_name)\n",
    "        file_set.add(rel_file)\n",
    "file_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>tag</th>\n",
       "      <th>File_Format</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>doc</td>\n",
       "      <td>nav Kukreja.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>hore Appala.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>sh Kumar BA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>tya Agarwal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Rejected\\Rejected - Project Management Office\\...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>doc</td>\n",
       "      <td>Taru Sharma.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Rejected\\Rejected - Project Management Office\\...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>ashi Sharma.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>man Rathore.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>doc</td>\n",
       "      <td>jan Rajguru.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>urabh Gupta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>pdf</td>\n",
       "      <td>ndra Pratap.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>doc</td>\n",
       "      <td>g\\Priyanshu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Rejected\\Rejected - Project Management Office\\...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>doc</td>\n",
       "      <td>Satabdi Sen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Rejected\\Rejected - Big Data Developer\\Shubham...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>doc</td>\n",
       "      <td>bham Shukla.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>doc</td>\n",
       "      <td>nkit Mittal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>inder Singh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Rejected\\Tableau\\Arvind Salunkhe.docx</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>nd Salunkhe.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Rejected\\Tableau\\Jeevesh Rath.docx</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>eevesh Rath.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Rejected\\Tableau\\peeyush Gupta.doc</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>doc</td>\n",
       "      <td>eyush Gupta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>pdf</td>\n",
       "      <td>nkur Gulati.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Rejected\\MSBI\\Gitika_Mishra_4_5yr_Exp_MSBI_Dev...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>I_Developer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>Ayush Goyal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>doc</td>\n",
       "      <td>anish Kumar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Rejected\\Rejected - Project Management Office\\...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>doc</td>\n",
       "      <td>Manish Atal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>ridh Sahney.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>ngh Matharu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Rejected\\Rejected - Project Management Office\\...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>Singh Rana.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>der Chamoli.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>ukesh Kumar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Rejected\\Rejected - Project Management Office\\...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>PRITI SINGH.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>doc</td>\n",
       "      <td>)\\Varun Das.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Rejected\\Resume_Pradeep.docx</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>ume_Pradeep.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>pdf</td>\n",
       "      <td>ailaj Kumar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Rejected\\Tableau\\Pavan Kumar CHVRN.DOC</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>DOC</td>\n",
       "      <td>Kumar CHVRN.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Rejected\\MSBI\\Sahil_Kadarbhai_Resume.doc</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>doc</td>\n",
       "      <td>bhai_Resume.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>vneet Kumar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Rejected\\Rejected - Big Data Developer\\Rishi R...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>doc</td>\n",
       "      <td>r\\Rishi Raj.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>Sahil Gupta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Rejected\\Rejected - Big Data Developer\\Mahesh ...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>ahesh Gupta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Rejected\\Rejected - Big Data Developer\\Tarvind...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>inder Singh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Rejected\\Rejected - SQL Server, BA, Investment...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>pdf</td>\n",
       "      <td>al Sachdeva.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rejected\\Rejected - Project Management Office\\...</td>\n",
       "      <td>Rejected</td>\n",
       "      <td>docx</td>\n",
       "      <td>ant Chauhan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Selected\\MSBI\\Sourabh Muchhal.docx</td>\n",
       "      <td>Selected</td>\n",
       "      <td>docx</td>\n",
       "      <td>abh Muchhal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Selected\\Tableau\\Madheswaran Sivalingam_16yrs_...</td>\n",
       "      <td>Selected</td>\n",
       "      <td>docx</td>\n",
       "      <td>yrs_Chennai.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Selected\\Tableau\\Mohammad Faizan.doc</td>\n",
       "      <td>Selected</td>\n",
       "      <td>doc</td>\n",
       "      <td>mmad Faizan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Selected\\Tableau\\Vijay Kumar Ajarla-13yrs-Tabl...</td>\n",
       "      <td>Selected</td>\n",
       "      <td>docx</td>\n",
       "      <td>t-Hyderabad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Selected\\Selected - SQL Server, BA, Investment...</td>\n",
       "      <td>Selected</td>\n",
       "      <td>docx</td>\n",
       "      <td>nil Dhamani.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Selected\\MSBI\\Shubham Garg.doc</td>\n",
       "      <td>Selected</td>\n",
       "      <td>doc</td>\n",
       "      <td>hubham Garg.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Selected\\Selected - Project Management Office\\...</td>\n",
       "      <td>Selected</td>\n",
       "      <td>pdf</td>\n",
       "      <td>Parul Batra.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Selected\\Selected - SQL Server, BA, Investment...</td>\n",
       "      <td>Selected</td>\n",
       "      <td>docx</td>\n",
       "      <td>idhi Khanna.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Selected\\Selected - SQL Server, BA, Investment...</td>\n",
       "      <td>Selected</td>\n",
       "      <td>docx</td>\n",
       "      <td>tibha Gupta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Selected\\MSBI\\VivekShilimkar.doc</td>\n",
       "      <td>Selected</td>\n",
       "      <td>doc</td>\n",
       "      <td>ekShilimkar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Selected\\Tableau\\Manish Amin.docx</td>\n",
       "      <td>Selected</td>\n",
       "      <td>docx</td>\n",
       "      <td>Manish Amin.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Selected\\Selected - Big Data Developer\\AVDHESH...</td>\n",
       "      <td>Selected</td>\n",
       "      <td>pdf</td>\n",
       "      <td>SH SACHDEVA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Selected\\Selected - Project Management Office\\...</td>\n",
       "      <td>Selected</td>\n",
       "      <td>doc</td>\n",
       "      <td>ti Kathuria.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Selected\\MSBI\\Bibhudatta_Hotta_Resume.docx</td>\n",
       "      <td>Selected</td>\n",
       "      <td>docx</td>\n",
       "      <td>otta_Resume.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Selected\\Selected - SQL Server, BA, Investment...</td>\n",
       "      <td>Selected</td>\n",
       "      <td>docx</td>\n",
       "      <td>Nishu Jain.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Selected\\SHUBHAM AGRAWAL.doc</td>\n",
       "      <td>Selected</td>\n",
       "      <td>doc</td>\n",
       "      <td>HAM AGRAWAL.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Selected\\MSBI\\Bikash Singh.docx</td>\n",
       "      <td>Selected</td>\n",
       "      <td>docx</td>\n",
       "      <td>ikash Singh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Selected\\Selected - SQL Server, BA, Investment...</td>\n",
       "      <td>Selected</td>\n",
       "      <td>docx</td>\n",
       "      <td>mya Agarwal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Selected\\Selected - SQL Server, BA, Investment...</td>\n",
       "      <td>Selected</td>\n",
       "      <td>docx</td>\n",
       "      <td>deep Singla.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Path       tag File_Format  \\\n",
       "0    Rejected\\Rejected - SQL Server, BA, Investment...  Rejected         doc   \n",
       "89   Rejected\\Rejected - SQL Server, BA, Investment...  Rejected        docx   \n",
       "87   Rejected\\Rejected - SQL Server, BA, Investment...  Rejected        docx   \n",
       "85   Rejected\\Rejected - SQL Server, BA, Investment...  Rejected        docx   \n",
       "84   Rejected\\Rejected - Project Management Office\\...  Rejected         doc   \n",
       "83   Rejected\\Rejected - Project Management Office\\...  Rejected        docx   \n",
       "82   Rejected\\Rejected - SQL Server, BA, Investment...  Rejected        docx   \n",
       "81   Rejected\\Rejected - SQL Server, BA, Investment...  Rejected         doc   \n",
       "79   Rejected\\Rejected - SQL Server, BA, Investment...  Rejected        docx   \n",
       "78   Rejected\\Rejected - SQL Server, BA, Investment...  Rejected         pdf   \n",
       "77   Rejected\\Rejected - SQL Server, BA, Investment...  Rejected         doc   \n",
       "76   Rejected\\Rejected - Project Management Office\\...  Rejected         doc   \n",
       "75   Rejected\\Rejected - Big Data Developer\\Shubham...  Rejected         doc   \n",
       "74   Rejected\\Rejected - SQL Server, BA, Investment...  Rejected         doc   \n",
       "73   Rejected\\Rejected - SQL Server, BA, Investment...  Rejected        docx   \n",
       "71               Rejected\\Tableau\\Arvind Salunkhe.docx  Rejected        docx   \n",
       "70                  Rejected\\Tableau\\Jeevesh Rath.docx  Rejected        docx   \n",
       "69                  Rejected\\Tableau\\peeyush Gupta.doc  Rejected         doc   \n",
       "68   Rejected\\Rejected - SQL Server, BA, Investment...  Rejected         pdf   \n",
       "67   Rejected\\MSBI\\Gitika_Mishra_4_5yr_Exp_MSBI_Dev...  Rejected        docx   \n",
       "66   Rejected\\Rejected - SQL Server, BA, Investment...  Rejected        docx   \n",
       "64   Rejected\\Rejected - SQL Server, BA, Investment...  Rejected         doc   \n",
       "125  Rejected\\Rejected - Project Management Office\\...  Rejected         doc   \n",
       "62   Rejected\\Rejected - SQL Server, BA, Investment...  Rejected        docx   \n",
       "61   Rejected\\Rejected - SQL Server, BA, Investment...  Rejected        docx   \n",
       "60   Rejected\\Rejected - Project Management Office\\...  Rejected        docx   \n",
       "90   Rejected\\Rejected - SQL Server, BA, Investment...  Rejected        docx   \n",
       "91   Rejected\\Rejected - SQL Server, BA, Investment...  Rejected        docx   \n",
       "92   Rejected\\Rejected - Project Management Office\\...  Rejected        docx   \n",
       "94   Rejected\\Rejected - SQL Server, BA, Investment...  Rejected         doc   \n",
       "..                                                 ...       ...         ...   \n",
       "53                        Rejected\\Resume_Pradeep.docx  Rejected        docx   \n",
       "37   Rejected\\Rejected - SQL Server, BA, Investment...  Rejected         pdf   \n",
       "36              Rejected\\Tableau\\Pavan Kumar CHVRN.DOC  Rejected         DOC   \n",
       "35            Rejected\\MSBI\\Sahil_Kadarbhai_Resume.doc  Rejected         doc   \n",
       "54   Rejected\\Rejected - SQL Server, BA, Investment...  Rejected        docx   \n",
       "48   Rejected\\Rejected - Big Data Developer\\Rishi R...  Rejected         doc   \n",
       "55   Rejected\\Rejected - SQL Server, BA, Investment...  Rejected        docx   \n",
       "33   Rejected\\Rejected - Big Data Developer\\Mahesh ...  Rejected        docx   \n",
       "45   Rejected\\Rejected - Big Data Developer\\Tarvind...  Rejected        docx   \n",
       "44   Rejected\\Rejected - SQL Server, BA, Investment...  Rejected         pdf   \n",
       "49   Rejected\\Rejected - Project Management Office\\...  Rejected        docx   \n",
       "88                  Selected\\MSBI\\Sourabh Muchhal.docx  Selected        docx   \n",
       "2    Selected\\Tableau\\Madheswaran Sivalingam_16yrs_...  Selected        docx   \n",
       "124               Selected\\Tableau\\Mohammad Faizan.doc  Selected         doc   \n",
       "50   Selected\\Tableau\\Vijay Kumar Ajarla-13yrs-Tabl...  Selected        docx   \n",
       "65   Selected\\Selected - SQL Server, BA, Investment...  Selected        docx   \n",
       "107                     Selected\\MSBI\\Shubham Garg.doc  Selected         doc   \n",
       "72   Selected\\Selected - Project Management Office\\...  Selected         pdf   \n",
       "15   Selected\\Selected - SQL Server, BA, Investment...  Selected        docx   \n",
       "86   Selected\\Selected - SQL Server, BA, Investment...  Selected        docx   \n",
       "38                    Selected\\MSBI\\VivekShilimkar.doc  Selected         doc   \n",
       "23                   Selected\\Tableau\\Manish Amin.docx  Selected        docx   \n",
       "80   Selected\\Selected - Big Data Developer\\AVDHESH...  Selected         pdf   \n",
       "97   Selected\\Selected - Project Management Office\\...  Selected         doc   \n",
       "93          Selected\\MSBI\\Bibhudatta_Hotta_Resume.docx  Selected        docx   \n",
       "34   Selected\\Selected - SQL Server, BA, Investment...  Selected        docx   \n",
       "29                        Selected\\SHUBHAM AGRAWAL.doc  Selected         doc   \n",
       "31                     Selected\\MSBI\\Bikash Singh.docx  Selected        docx   \n",
       "112  Selected\\Selected - SQL Server, BA, Investment...  Selected        docx   \n",
       "56   Selected\\Selected - SQL Server, BA, Investment...  Selected        docx   \n",
       "\n",
       "            Label  \n",
       "0    nav Kukreja.  \n",
       "89   hore Appala.  \n",
       "87   sh Kumar BA.  \n",
       "85   tya Agarwal.  \n",
       "84   Taru Sharma.  \n",
       "83   ashi Sharma.  \n",
       "82   man Rathore.  \n",
       "81   jan Rajguru.  \n",
       "79   urabh Gupta.  \n",
       "78   ndra Pratap.  \n",
       "77   g\\Priyanshu.  \n",
       "76   Satabdi Sen.  \n",
       "75   bham Shukla.  \n",
       "74   nkit Mittal.  \n",
       "73   inder Singh.  \n",
       "71   nd Salunkhe.  \n",
       "70   eevesh Rath.  \n",
       "69   eyush Gupta.  \n",
       "68   nkur Gulati.  \n",
       "67   I_Developer.  \n",
       "66   Ayush Goyal.  \n",
       "64   anish Kumar.  \n",
       "125  Manish Atal.  \n",
       "62   ridh Sahney.  \n",
       "61   ngh Matharu.  \n",
       "60    Singh Rana.  \n",
       "90   der Chamoli.  \n",
       "91   ukesh Kumar.  \n",
       "92   PRITI SINGH.  \n",
       "94   )\\Varun Das.  \n",
       "..            ...  \n",
       "53   ume_Pradeep.  \n",
       "37   ailaj Kumar.  \n",
       "36   Kumar CHVRN.  \n",
       "35   bhai_Resume.  \n",
       "54   vneet Kumar.  \n",
       "48   r\\Rishi Raj.  \n",
       "55   Sahil Gupta.  \n",
       "33   ahesh Gupta.  \n",
       "45   inder Singh.  \n",
       "44   al Sachdeva.  \n",
       "49   ant Chauhan.  \n",
       "88   abh Muchhal.  \n",
       "2    yrs_Chennai.  \n",
       "124  mmad Faizan.  \n",
       "50   t-Hyderabad.  \n",
       "65   nil Dhamani.  \n",
       "107  hubham Garg.  \n",
       "72   Parul Batra.  \n",
       "15   idhi Khanna.  \n",
       "86   tibha Gupta.  \n",
       "38   ekShilimkar.  \n",
       "23   Manish Amin.  \n",
       "80   SH SACHDEVA.  \n",
       "97   ti Kathuria.  \n",
       "93   otta_Resume.  \n",
       "34    Nishu Jain.  \n",
       "29   HAM AGRAWAL.  \n",
       "31   ikash Singh.  \n",
       "112  mya Agarwal.  \n",
       "56   deep Singla.  \n",
       "\n",
       "[127 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(file_set, columns = ['Path'])\n",
    "df['tag'] =df.Path.str.slice(0, 8)\n",
    "df['File_Format'] = df.Path.str.extract(r'\\b(\\w+)$', expand=True)\n",
    "df.sort_values('tag',inplace=True)#sorting on Tag\n",
    "df['Label']=df['Path'].str.extract('(...........\\\\.)', expand=True)\n",
    "dataset['word_count'] = dataset['abstract1'].apply(lambda x: len(str(x).split(\" \")))\n",
    "dataset[['abstract1','word_count']].head()\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hey', 'there', 'this', 'sample', 'review', 'happens', 'blah', 'contain', 'happened', 'punctuation', 'universal', 'right', 'right', 'contained']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\NEW\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\NEW\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Text pre-processing\n",
    "\"\"\"removes punctuation, stopwords, and returns a list of the remaining words, or tokens\"\"\"\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "import string\n",
    "def text_process(text):\n",
    "    '''\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Return the cleaned text as a list of words\n",
    "    4. Remove words\n",
    "    '''\n",
    "    stemmer = WordNetLemmatizer()\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join([i for i in nopunc if not i.isdigit()])\n",
    "    nopunc =  [word.lower() for word in nopunc.split() if word not in stopwords.words('english')]\n",
    "    return [stemmer.lemmatize(word) for word in nopunc]\n",
    "\n",
    "#testing the function with a sample text#\n",
    "sample_text = \"Hey There! This is a Sample review, which 123happens {blah}%456 to contain happened punctuations universal rights of right contained.\"\n",
    "print(text_process(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'df'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-150eadbf585b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdocx2txt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_process'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtext_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocx2txt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Path'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'df'"
     ]
    }
   ],
   "source": [
    "import docx2txt\n",
    "df['text_process']=text_process(docx2txt.process.df['Path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-68-a906e94a0bad>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-68-a906e94a0bad>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    r1[][]=text_process(value)\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for value in df[\"Path\"]: \n",
    "    r1[]=text_process(value)\n",
    "       \n",
    "df[\"text_process\"] = result \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx2txt\n",
    " \n",
    "# read in word file\n",
    "result = docx2txt.process(\"C:/Users/NEW/Desktop/Udemy/Resume/Resume_Ch_June.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tag'] =df.Path.str.slice(0, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/NEW/Desktop/Udemy/Resume/dataset ['Rejected', 'Selected'] []\n",
      "C:/Users/NEW/Desktop/Udemy/Resume/dataset\\Rejected ['MSBI', 'Rejected - Big Data Developer', 'Rejected - Project Management Office', 'Rejected - SQL Server, BA, Investment Banking', 'Tableau'] ['Resume_ Neetu Kumari.docx', 'Resume_Pradeep.docx', 'T2S_Chirag Dhamija_2.6 years_Gurgaon.pdf', 'T2S_Gunmeetkumar_3.5 years_noida.doc']\n",
      "C:/Users/NEW/Desktop/Udemy/Resume/dataset\\Rejected\\MSBI [] ['Gitika_Mishra_4_5yr_Exp_MSBI_Developer.docx', 'Hemant_Nikam_MSBI.doc', 'Jeweel Roy.docx', 'Ravi Shankar.docx', 'Sahil_Kadarbhai_Resume.doc', 'Shruti Tembhurnikar.docx', 'Snehal Giri.docx']\n",
      "C:/Users/NEW/Desktop/Udemy/Resume/dataset\\Rejected\\Rejected - Big Data Developer [] ['Anupam Gaur.doc', 'ArvindKumarThakur.doc', 'Ashwani Kumar.doc', 'Big Data Resume VineetGarg.pdf', 'Deepak Resume.doc', 'Kritika_Joshi_BigdataProfile.docx', 'Lokesh Gupta.docx', 'Mahesh Gupta.docx', 'Praveen Agrawal.docx', 'Rishi Raj.doc', 'Shubham Shukla.doc', 'Tarvinder Singh.docx', 'Ved Prakash.doc']\n",
      "C:/Users/NEW/Desktop/Udemy/Resume/dataset\\Rejected\\Rejected - Project Management Office ['Rejected - Project Management Office (1)'] ['Ankita Sinha.docx', 'Chakravarti Singh.pdf', 'Hasanuzzaman.pdf', 'Manish Atal.doc', 'Prafulla_CV.pdf', 'Priya Mahur.pdf', 'Satabdi Sen.doc', 'Shashikant Chauhan.docx', 'Shruti Mishra.docx', 'Sonu Singh Rana.docx', 'Taru Sharma.doc', 'Vikash Kumar Sharma.docx']\n",
      "C:/Users/NEW/Desktop/Udemy/Resume/dataset\\Rejected\\Rejected - Project Management Office\\Rejected - Project Management Office (1) [] ['Heena Prashar.pdf', 'Manjari_Resume.doc', 'PRITI SINGH.docx', 'Rashi Sharma.docx']\n",
      "C:/Users/NEW/Desktop/Udemy/Resume/dataset\\Rejected\\Rejected - SQL Server, BA, Investment Banking ['Rejected - SQL Server, BA, Investment Banking (1)', 'Rejected Profiles - SQL Server, BA, Investment Banking'] ['Abhinav Kukreja.doc', 'Aditya Agarwal.docx', 'Avneet Kumar.docx', 'Balpreet Kaur.pdf', 'Deshant Digani.doc', 'Devender Chamoli.docx', 'Inderbir Singh Matharu.docx', 'Mohit Chandra Saxena.pdf', 'Mohit Manocha.doc', 'Piyush Kalra.doc', 'Rahul Garg.doc', 'Sankalp Pandey.docx', 'Smridh Sahney.docx', 'Sumit Gupta.doc', 'Yashika Srivastava.docx']\n",
      "C:/Users/NEW/Desktop/Udemy/Resume/dataset\\Rejected\\Rejected - SQL Server, BA, Investment Banking\\Rejected - SQL Server, BA, Investment Banking (1) [] ['Ankit Mittal.doc', 'Ankur Gulati.pdf', 'Ayush Goyal.docx', 'Deepak Sharma.pdf', 'Divjyot Talwar.pdf', 'Junaid Hakeem.docx', 'Laxman Rathore.docx', 'Mayank Parashar.pdf', 'Nancy Sood.docx', 'Sandeep Kumar.docx', 'Saurabh Gupta.docx', 'Shailaj Kumar.pdf', 'Varun Das.doc']\n",
      "C:/Users/NEW/Desktop/Udemy/Resume/dataset\\Rejected\\Rejected - SQL Server, BA, Investment Banking\\Rejected Profiles - SQL Server, BA, Investment Banking [] ['Abhishek Gupta.docx', 'Ankur Singh Kashyap.doc', 'Anwesha Sengupta.docx', 'Ashish Marwah.doc', 'Devender Dagar.doc', 'Hitesh Puri.doc', 'Jagwinder Singh.docx', 'Jeevan Gurpratap.docx', 'Jyoti Jindal.doc', 'Ketan Aralkar.docx', 'Krishna Kishore Appala.docx', 'Kunal Sachdeva.docx', 'Kunal Sachdeva.pdf', 'Lokesh Gupta.docx', 'Manish Kumar BA.docx', 'Manish Kumar.doc', 'ManojKumar.docx', 'Manoranjan Rajguru.doc', 'Mukesh Kumar.docx', 'Nikhil Gupta.docx', 'Priyanshu.doc', 'Profile - Jitendra Pratap.pdf', 'Profile - Nishant Dubey.pdf', 'Profile - Stuti Singh.doc', 'Rahul Sharma.docx', 'Sahil Gupta.docx', 'Sheelabhadra Singhdeo.doc', 'Shivam Goel.docx', 'Sudama Singh Thakur.doc', 'Taru Gangal.pdf', 'Yash Kumar Kaushik.docx']\n",
      "C:/Users/NEW/Desktop/Udemy/Resume/dataset\\Rejected\\Tableau [] ['Anand Sahu.pdf', 'Arvind Salunkhe.docx', 'Jeevesh Rath.docx', 'MaheshGupta_15 yrs_Pune.doc', 'Parag Khatri.doc', 'Pavan Kumar CHVRN.DOC', 'peeyush Gupta.doc', 'Prashant Naik-11.8yrs-Tableau Architect-Pune.docx', 'Premnath R J-14yrs-Tableau Architect-Bangalore.doc']\n",
      "C:/Users/NEW/Desktop/Udemy/Resume/dataset\\Selected ['MSBI', 'Selected - Big Data Developer', 'Selected - Project Management Office', 'Selected - SQL Server, BA, Investment Banking', 'Tableau'] ['SHUBHAM AGRAWAL.doc']\n",
      "C:/Users/NEW/Desktop/Udemy/Resume/dataset\\Selected\\MSBI [] ['Bibhudatta_Hotta_Resume.docx', 'Bikash Singh.docx', 'Shubham Garg.doc', 'Sourabh Muchhal.docx', 'VivekShilimkar.doc']\n",
      "C:/Users/NEW/Desktop/Udemy/Resume/dataset\\Selected\\Selected - Big Data Developer [] ['AVDHESH SACHDEVA.pdf']\n",
      "C:/Users/NEW/Desktop/Udemy/Resume/dataset\\Selected\\Selected - Project Management Office [] ['Aditi Kathuria.doc', 'Parul Batra.pdf']\n",
      "C:/Users/NEW/Desktop/Udemy/Resume/dataset\\Selected\\Selected - SQL Server, BA, Investment Banking [] ['Gagandeep Singla.docx', 'Nidhi Khanna.docx', 'Pratibha Gupta.docx', 'Profile - Nishu Jain.docx', 'Saumya Agarwal.docx', 'Swapnil Dhamani.docx']\n",
      "C:/Users/NEW/Desktop/Udemy/Resume/dataset\\Selected\\Tableau [] ['Madheswaran Sivalingam_16yrs_Chennai.docx', 'Manish Amin.docx', 'Mohammad Faizan.doc', 'Vijay Kumar Ajarla-13yrs-Tableau Architect-Hyderabad.docx']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "path = \"C:/Users/NEW/Desktop/Udemy/Resume/dataset\"\n",
    "for root,d_names,f_names in os.walk(path):\n",
    "\tprint (root, d_names, f_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rejected', 'Selected']\n",
      "['MSBI', 'Rejected - Big Data Developer', 'Rejected - Project Management Office', 'Rejected - SQL Server, BA, Investment Banking', 'Tableau']\n",
      "[]\n",
      "[]\n",
      "['Rejected - Project Management Office (1)']\n",
      "[]\n",
      "['Rejected - SQL Server, BA, Investment Banking (1)', 'Rejected Profiles - SQL Server, BA, Investment Banking']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['MSBI', 'Selected - Big Data Developer', 'Selected - Project Management Office', 'Selected - SQL Server, BA, Investment Banking', 'Tableau']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "path = \"C:/Users/NEW/Desktop/Udemy/Resume/dataset\"\n",
    "for dirpath, dirs, files in os.walk(path):\n",
    "\tprint(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rejected    108\n",
       "Selected     19\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "docx    63\n",
       "doc     42\n",
       "pdf     21\n",
       "DOC      1\n",
       "Name: File_Format, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.File_Format.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
